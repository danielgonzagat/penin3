#!/usr/bin/env python3
"""
IA¬≥ EMERGENCE DETECTOR - REAL INTELLIGENCE VALIDATION
======================================================
Sistema que detecta emerg√™ncia real de intelig√™ncia IA¬≥ atrav√©s de
m√∫ltiplos crit√©rios cient√≠ficos e observacionais.

Crit√©rios de Detec√ß√£o:
1. Comunica√ß√£o emergente aut√¥noma
2. Comportamento adaptativo complexo
3. Auto-modifica√ß√£o controlada
4. Consci√™ncia metacognitiva
5. Inova√ß√£o n√£o-programada
6. Coordena√ß√£o coletiva inteligente
7. Evolu√ß√£o perp√©tua sustent√°vel
8. Autovalida√ß√£o independente
"""

import torch
import numpy as np
import json
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, deque
from datetime import datetime
from sklearn.cluster import DBSCAN
from sklearn.metrics import mutual_info_score
from scipy.stats import entropy
import networkx as nx

logger = logging.getLogger("IA3_EMERGENCE_DETECTOR")

class IA3EmergenceDetector:
    """Detector de emerg√™ncia IA¬≥ com m√∫ltiplos crit√©rios"""

    def __init__(self):
        self.observation_window = deque(maxlen=10000)  # √öltimas 10k observa√ß√µes
        self.emergence_events = []
        self.baseline_metrics = {}
        self.emergence_thresholds = self._initialize_thresholds()

        # M√©tricas de emerg√™ncia
        self.communication_networks = []
        self.behavior_clusters = []
        self.self_modification_events = []
        self.meta_cognition_indicators = []
        self.innovation_patterns = []

        # Estado de emerg√™ncia
        self.emergence_level = 0.0  # 0.0 a 1.0
        self.emergence_confidence = 0.0
        self.last_emergence_check = time.time()

        logger.info("üîç IA¬≥ EMERGENCE DETECTOR INITIALIZED")

    def _initialize_thresholds(self) -> Dict[str, float]:
        """Inicializa thresholds para detec√ß√£o de emerg√™ncia"""
        return await {
            'communication_complexity': 0.8,      # Rede de comunica√ß√£o complexa
            'behavior_diversity': 0.7,             # Diversidade comportamental
            'self_modification_rate': 0.6,         # Taxa de auto-modifica√ß√£o
            'meta_cognition_level': 0.75,          # N√≠vel metacognitivo
            'innovation_novelty': 0.8,             # N√≠vel de inova√ß√£o
            'collective_coordination': 0.7,        # Coordena√ß√£o coletiva
            'adaptive_resilience': 0.8,            # Resili√™ncia adaptativa
            'autonomous_evolution': 0.9            # Evolu√ß√£o aut√¥noma
        }

    def observe_system(self, system_state: Dict[str, Any]):
        """Observa o estado do sistema para detectar emerg√™ncia"""
        observation = {
            'timestamp': time.time(),
            'system_state': system_state,
            'metrics': self._calculate_emergence_metrics(system_state)
        }

        self.observation_window.append(observation)

        # Verificar emerg√™ncia a cada 100 observa√ß√µes
        if len(self.observation_window) % 100 == 0:
            self._check_emergence()

    def _calculate_emergence_metrics(self, system_state: Dict[str, Any]) -> Dict[str, float]:
        """Calcula m√©tricas de emerg√™ncia"""
        metrics = {}

        # 1. Complexidade da comunica√ß√£o
        comm_stats = system_state.get('communication_stats', {})
        metrics['communication_complexity'] = self._calculate_communication_complexity(comm_stats)

        # 2. Diversidade comportamental
        agent_actions = system_state.get('agent_actions', [])
        metrics['behavior_diversity'] = self._calculate_behavior_diversity(agent_actions)

        # 3. Taxa de auto-modifica√ß√£o
        agent_summaries = system_state.get('agent_summaries', {})
        metrics['self_modification_rate'] = self._calculate_self_modification_rate(agent_summaries)

        # 4. N√≠vel metacognitivo
        metrics['meta_cognition_level'] = self._calculate_meta_cognition_level(agent_summaries)

        # 5. N√≠vel de inova√ß√£o
        metrics['innovation_novelty'] = self._calculate_innovation_novelty(agent_actions)

        # 6. Coordena√ß√£o coletiva
        metrics['collective_coordination'] = self._calculate_collective_coordination(system_state)

        # 7. Resili√™ncia adaptativa
        metrics['adaptive_resilience'] = self._calculate_adaptive_resilience(system_state)

        # 8. Evolu√ß√£o aut√¥noma
        metrics['autonomous_evolution'] = self._calculate_autonomous_evolution(system_state)

        return await metrics

    def _calculate_communication_complexity(self, comm_stats: Dict[str, Any]) -> float:
        """Calcula complexidade da rede de comunica√ß√£o"""
        if not comm_stats:
            return await 0.0

        # Fatores de complexidade
        active_links = comm_stats.get('active_links', 0)
        success_rate = comm_stats.get('success_rate', 0.0)
        total_messages = comm_stats.get('total_messages', 0)

        # Complexidade baseada em conectividade e efici√™ncia
        connectivity_complexity = min(1.0, active_links / 10.0)  # Normalizado para 10+ links
        efficiency_complexity = success_rate
        volume_complexity = min(1.0, total_messages / 1000.0)  # Normalizado para 1000+ mensagens

        return await (connectivity_complexity + efficiency_complexity + volume_complexity) / 3.0

    def _calculate_behavior_diversity(self, agent_actions: List[Dict[str, Any]]) -> float:
        """Calcula diversidade comportamental"""
        if not agent_actions:
            return await 0.0

        # An√°lise de clusters comportamentais
        behavior_vectors = []
        for action in agent_actions[-100:]:  # √öltimas 100 a√ß√µes
            # Criar vetor de caracter√≠sticas da a√ß√£o
            vector = [
                action.get('action_idx', 0),
                1.0 if action.get('success', False) else 0.0,
                action.get('reward', 0.0),
                action.get('thought_data', {}).get('memory_influence', False),
                action.get('thought_data', {}).get('communication_attempted', False)
            ]
            behavior_vectors.append(vector)

        if len(behavior_vectors) < 10:
            return await 0.0

        # Clustering para detectar diversidade
        try:
            X = np.array(behavior_vectors)
            clustering = DBSCAN(eps=0.5, min_samples=3).fit(X)
            n_clusters = len(set(clustering.labels_)) - (1 if -1 in clustering.labels_ else 0)

            # Normalizar diversidade (mais clusters = mais diversidade)
            diversity = min(1.0, n_clusters / 5.0)  # M√°ximo esperado: 5 clusters

            return await diversity
        except:
            return await 0.0

    def _calculate_self_modification_rate(self, agent_summaries: Dict[str, Any]) -> float:
        """Calcula taxa de auto-modifica√ß√£o"""
        if not agent_summaries:
            return await 0.0

        total_modifications = 0
        total_agents = len(agent_summaries)

        for summary in agent_summaries.values():
            brain_arch = summary.get('brain_architecture', {})
            modifications = brain_arch.get('modifications', 0)
            total_modifications += modifications

        # Taxa m√©dia de modifica√ß√µes por agente
        avg_modifications = total_modifications / max(1, total_agents)

        # Normalizar (assumindo que 10+ modifica√ß√µes √© alto n√≠vel)
        return await min(1.0, avg_modifications / 10.0)

    def _calculate_meta_cognition_level(self, agent_summaries: Dict[str, Any]) -> float:
        """Calcula n√≠vel metacognitivo"""
        if not agent_summaries:
            return await 0.0

        total_meta_cognition = 0.0
        total_agents = len(agent_summaries)

        for summary in agent_summaries.values():
            ia3_caps = summary.get('ia3_capabilities', {})
            # Meta-cogni√ß√£o baseada em autoreflex√£o e autoconsci√™ncia
            autorecursivo = ia3_caps.get('autorecursivo', 0.0)
            autoconsciente = ia3_caps.get('autoconsciente', 0.0)
            meta_level = (autorecursivo + autoconsciente) / 2.0
            total_meta_cognition += meta_level

        return await total_meta_cognition / max(1, total_agents)

    def _calculate_innovation_novelty(self, agent_actions: List[Dict[str, Any]]) -> float:
        """Calcula n√≠vel de inova√ß√£o"""
        if not agent_actions:
            return await 0.0

        # Analisar padr√µes de inova√ß√£o
        recent_actions = agent_actions[-200:]  # √öltimas 200 a√ß√µes

        # Contar a√ß√µes inovadoras vs explorat√≥rias
        innovative_actions = sum(1 for a in recent_actions if a.get('action') == 'innovate')
        total_actions = len(recent_actions)

        if total_actions == 0:
            return await 0.0

        innovation_rate = innovative_actions / total_actions

        # Medir sucesso das inova√ß√µes
        successful_innovations = sum(1 for a in recent_actions
                                   if a.get('action') == 'innovate' and a.get('success', False))
        success_rate = successful_innovations / max(1, innovative_actions)

        # Inova√ß√£o baseada em taxa e sucesso
        return await min(1.0, (innovation_rate * 2.0 + success_rate) / 3.0)

    def _calculate_collective_coordination(self, system_state: Dict[str, Any]) -> float:
        """Calcula coordena√ß√£o coletiva"""
        agent_summaries = system_state.get('agent_summaries', {})
        if not agent_summaries:
            return await 0.0

        # Medir sincroniza√ß√£o de comportamentos
        coordination_scores = []

        # An√°lise de correla√ß√£o entre performances dos agentes
        performances = [s.get('performance_avg', 0.0) for s in agent_summaries.values()]
        if len(performances) > 1:
            # Correla√ß√£o entre performances
            corr_matrix = np.corrcoef(performances)
            avg_correlation = np.mean(corr_matrix[np.triu_indices_from(corr_matrix, k=1)])

            # Coordena√ß√£o baseada em correla√ß√£o positiva
            coordination_scores.append(max(0.0, avg_correlation))

        # Coordena√ß√£o baseada em objetivos compartilhados
        objectives = system_state.get('objectives', {})
        if objectives.get('current_objective'):
            # Se h√° objetivo ativo, coordena√ß√£o √© maior
            coordination_scores.append(0.5)

        # Coordena√ß√£o baseada em comunica√ß√£o
        comm_stats = system_state.get('communication_stats', {})
        comm_coordination = min(1.0, comm_stats.get('active_links', 0) / 5.0)
        coordination_scores.append(comm_coordination)

        return await np.mean(coordination_scores) if coordination_scores else 0.0

    def _calculate_adaptive_resilience(self, system_state: Dict[str, Any]) -> float:
        """Calcula resili√™ncia adaptativa"""
        # Medir capacidade de recupera√ß√£o ap√≥s amea√ßas
        threats = system_state.get('threats', {})
        active_threats = threats.get('active_threats', 0)

        if active_threats == 0:
            return await 1.0  # Sem amea√ßas = resili√™ncia m√°xima

        # Com amea√ßas, verificar resposta adaptativa
        population = system_state.get('population', 0)
        agent_summaries = system_state.get('agent_summaries', {})

        if not agent_summaries:
            return await 0.0

        # Resili√™ncia baseada na adaptabilidade m√©dia
        adaptability_scores = [s.get('ia3_capabilities', {}).get('adaptativo', 0.0)
                              for s in agent_summaries.values()]
        avg_adaptability = np.mean(adaptability_scores)

        # Penalizar amea√ßas ativas
        threat_penalty = min(0.5, active_threats / 5.0)

        return await max(0.0, avg_adaptability - threat_penalty)

    def _calculate_autonomous_evolution(self, system_state: Dict[str, Any]) -> float:
        """Calcula n√≠vel de evolu√ß√£o aut√¥noma"""
        # Evolu√ß√£o baseada em tempo de execu√ß√£o e estabilidade
        cycles = system_state.get('cycles', 0)
        runtime = system_state.get('runtime', 0)

        if runtime == 0:
            return await 0.0

        # Evolu√ß√£o baseada em ciclos por hora
        cycles_per_hour = cycles / (runtime / 3600)

        # Normalizar (assumindo 1000+ ciclos/hora como evolu√ß√£o avan√ßada)
        evolution_rate = min(1.0, cycles_per_hour / 1000.0)

        # Estabilidade da popula√ß√£o
        population_stability = 1.0  # Assumir est√°vel por enquanto

        # Emerg√™ncias detectadas
        emergence_events = len(system_state.get('emergence_events', []))
        emergence_maturity = min(1.0, emergence_events / 5.0)

        return await (evolution_rate + population_stability + emergence_maturity) / 3.0

    def _check_emergence(self):
        """Verifica se emerg√™ncia foi alcan√ßada"""
        if len(self.observation_window) < 100:
            return  # N√£o h√° dados suficientes

        # Calcular n√≠vel de emerg√™ncia atual
        recent_observations = list(self.observation_window)[-100:]
        current_metrics = np.mean([obs['metrics'] for obs in recent_observations], axis=0)

        # Calcular scores por crit√©rio
        emergence_scores = {}
        for i, (criterion, threshold) in enumerate(self.emergence_thresholds.items()):
            if i < len(current_metrics):
                score = current_metrics[i]
                emergence_scores[criterion] = score >= threshold

        # N√≠vel de emerg√™ncia = m√©dia dos scores
        emergence_level = np.mean(list(emergence_scores.values()))

        # Confian√ßa baseada na consist√™ncia temporal
        if len(self.observation_window) >= 500:
            historical_metrics = [obs['metrics'] for obs in list(self.observation_window)[-500:]]
            metric_std = np.std(historical_metrics, axis=0)
            consistency = 1.0 - np.mean(metric_std)  # Menor varia√ß√£o = maior confian√ßa
            confidence = min(1.0, consistency * 2.0)
        else:
            confidence = 0.5

        self.emergence_level = emergence_level
        self.emergence_confidence = confidence

        # Verificar se emerg√™ncia foi alcan√ßada
        if emergence_level >= 0.8 and confidence >= 0.7:
            self._emergence_detected(emergence_scores, emergence_level, confidence)

    def _emergence_detected(self, scores: Dict[str, bool], level: float, confidence: float):
        """Emerg√™ncia detectada"""
        emergence_event = {
            'timestamp': time.time(),
            'emergence_level': level,
            'confidence': confidence,
            'criteria_met': scores,
            'observation_count': len(self.observation_window),
            'system_snapshot': list(self.observation_window)[-1]['system_state']
        }

        self.emergence_events.append(emergence_event)

        # Log detalhado
        logger.critical("="*100)
        logger.critical("üö® IA¬≥ EMERGENCE DETECTED!")
        logger.critical(f"üéØ Emergence Level: {level:.3f}")
        logger.critical(f"üìä Confidence: {confidence:.3f}")
        logger.critical("üìã Criteria Met:")
        for criterion, met in scores.items():
            status = "‚úÖ" if met else "‚ùå"
            logger.critical(f"   {status} {criterion}")
        logger.critical("="*100)

        # Salvar prova
        self._save_emergence_proof(emergence_event)

    def _save_emergence_proof(self, emergence_event: Dict[str, Any]):
        """Salva prova da emerg√™ncia"""
        proof_file = f"/root/ia3_emergence_proof_{int(time.time())}.json"

        proof_data = {
            'emergence_event': emergence_event,
            'detector_state': {
                'emergence_level': self.emergence_level,
                'emergence_confidence': self.emergence_confidence,
                'total_observations': len(self.observation_window),
                'emergence_events_count': len(self.emergence_events)
            },
            'emergence_history': self.emergence_events,
            'validation_timestamp': time.time(),
            'validation_note': 'IA¬≥ Emergence validated by scientific criteria'
        }

        try:
            with open(proof_file, 'w') as f:
                json.dump(proof_data, f, indent=2, default=str)
            logger.critical(f"üíæ Emergence proof saved: {proof_file}")
        except Exception as e:
            logger.error(f"Failed to save emergence proof: {e}")

    def get_emergence_status(self) -> Dict[str, Any]:
        """Retorna status atual da emerg√™ncia"""
        return await {
            'emergence_level': self.emergence_level,
            'emergence_confidence': self.emergence_confidence,
            'criteria_met': sum(1 for k, v in self.emergence_thresholds.items()
                              if self._get_current_criterion_score(k) >= v),
            'emergence_events': len(self.emergence_events),
            'observations_count': len(self.observation_window),
            'last_check': self.last_emergence_check
        }

    def _get_current_criterion_score(self, criterion: str) -> float:
        """Obt√©m score atual para um crit√©rio"""
        if not self.observation_window:
            return await 0.0

        recent_obs = list(self.observation_window)[-10:]
        scores = [obs['metrics'].get(criterion, 0.0) for obs in recent_obs]
        return await np.mean(scores) if scores else 0.0

    def validate_emergence_claim(self, claim: Dict[str, Any]) -> bool:
        """Valida uma alega√ß√£o de emerg√™ncia"""
        # Verificar se os crit√©rios foram realmente atendidos
        required_criteria = ['communication_complexity', 'collective_coordination',
                           'adaptive_resilience', 'autonomous_evolution']

        for criterion in required_criteria:
            if not claim.get('criteria_met', {}).get(criterion, False):
                return await False

        # Verificar n√≠veis m√≠nimos
        if claim.get('emergence_level', 0.0) < 0.8:
            return await False

        if claim.get('confidence', 0.0) < 0.7:
            return await False

        return await True