#!/usr/bin/env python3
"""
SISTEMA COMPLETO DE EMERG√äNCIA DE INTELIG√äNCIA REAL
==================================================
Sistema unificado para fazer emergir intelig√™ncia real no conglomerado
"""

import os
import sys
import json
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import threading
import queue
import hashlib
import pickle
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import logging
from pathlib import Path
import random
import sqlite3
from collections import deque, Counter

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("IntelligenceEmergence")

# Configura√ß√£o para reprodutibilidade
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

class NeuralProcessor(nn.Module):
    """Processador neural avan√ßado com m√∫ltiplas arquiteturas"""
    
    def __init__(self, input_dim=64, hidden_dim=256, output_dim=128):
        super().__init__()
        
        # Arquitetura profunda com skip connections
        self.input_layer = nn.Linear(input_dim, hidden_dim)
        
        # Blocos residuais
        self.block1 = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )
        
        self.block2 = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.LayerNorm(hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )
        
        self.block3 = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )
        
        # Camada de sa√≠da
        self.output_layer = nn.Linear(hidden_dim, output_dim)
        
        # Attention mechanism
        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)
        
        # Memory bank
        self.memory_bank = nn.Parameter(torch.randn(10, hidden_dim))
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def forward(self, x):
        # Input processing
        if x.dim() == 1:
            x = x.unsqueeze(0)
        
        # Ajustar dimens√µes se necess√°rio
        if x.size(-1) != self.input_layer.in_features:
            if x.size(-1) > self.input_layer.in_features:
                x = x[:, :self.input_layer.in_features]
            else:
                padding = self.input_layer.in_features - x.size(-1)
                x = F.pad(x, (0, padding))
        
        # Forward pass com skip connections
        x = F.relu(self.input_layer(x))
        
        # Block 1 com residual
        residual = x
        x = self.block1(x)
        x = F.relu(x + residual)
        
        # Block 2 com residual
        residual = x
        x = self.block2(x)
        x = F.relu(x + residual)
        
        # Attention com memory bank
        memory = self.memory_bank.unsqueeze(0).expand(x.size(0), -1, -1)
        x_att = x.unsqueeze(1)
        x_att, _ = self.attention(x_att, memory, memory)
        x = x + x_att.squeeze(1)
        
        # Block 3 com residual
        residual = x
        x = self.block3(x)
        x = F.relu(x + residual)
        
        # Output
        x = self.output_layer(x)
        
        return x

class EvolutionEngine:
    """Motor de evolu√ß√£o gen√©tica"""
    
    def __init__(self, population_size=100, mutation_rate=0.1):
        self.population_size = population_size
        self.mutation_rate = mutation_rate
        self.population = []
        self.generation = 0
        self.best_fitness = 0
        self.fitness_history = []
        
        self._initialize_population()
    
    def _initialize_population(self):
        """Inicializa popula√ß√£o com genomas aleat√≥rios"""
        for i in range(self.population_size):
            genome = {
                'id': f"genome_{i}_{self.generation}",
                'genes': np.random.randn(128),
                'fitness': 0.0,
                'age': 0,
                'mutations': 0
            }
            self.population.append(genome)
    
    def evaluate_fitness(self, genome, environment_feedback):
        """Avalia fitness de um genoma"""
        # Fitness baseado em m√∫ltiplos fatores
        gene_diversity = np.std(genome['genes'])
        gene_complexity = np.mean(np.abs(np.diff(genome['genes'])))
        adaptation_score = environment_feedback.get('adaptation', 0.5)
        
        fitness = (gene_diversity * 0.3 + 
                  gene_complexity * 0.3 + 
                  adaptation_score * 0.4)
        
        genome['fitness'] = fitness
        return fitness
    
    def select_parents(self):
        """Sele√ß√£o por torneio"""
        tournament_size = 5
        parents = []
        
        for _ in range(2):
            tournament = random.sample(self.population, tournament_size)
            winner = max(tournament, key=lambda x: x['fitness'])
            parents.append(winner)
        
        return parents
    
    def crossover(self, parent1, parent2):
        """Crossover de dois genomas"""
        child = {
            'id': f"genome_{len(self.population)}_{self.generation}",
            'genes': np.zeros_like(parent1['genes']),
            'fitness': 0.0,
            'age': 0,
            'mutations': 0
        }
        
        # Crossover uniforme
        mask = np.random.random(len(parent1['genes'])) > 0.5
        child['genes'][mask] = parent1['genes'][mask]
        child['genes'][~mask] = parent2['genes'][~mask]
        
        return child
    
    def mutate(self, genome):
        """Muta√ß√£o do genoma"""
        if random.random() < self.mutation_rate:
            # Muta√ß√£o gaussiana
            mutation_strength = 0.1
            mutations = np.random.randn(len(genome['genes'])) * mutation_strength
            mask = np.random.random(len(genome['genes'])) < 0.1  # 10% dos genes
            genome['genes'][mask] += mutations[mask]
            genome['mutations'] += 1
    
    def evolve(self, environment_feedback):
        """Executa um ciclo de evolu√ß√£o"""
        # Avaliar fitness
        for genome in self.population:
            self.evaluate_fitness(genome, environment_feedback)
        
        # Ordenar por fitness
        self.population.sort(key=lambda x: x['fitness'], reverse=True)
        self.best_fitness = self.population[0]['fitness']
        self.fitness_history.append(self.best_fitness)
        
        # Nova gera√ß√£o
        new_population = []
        
        # Elitismo - manter os melhores
        elite_size = int(self.population_size * 0.1)
        new_population.extend(self.population[:elite_size])
        
        # Criar descendentes
        while len(new_population) < self.population_size:
            parents = self.select_parents()
            child = self.crossover(parents[0], parents[1])
            self.mutate(child)
            new_population.append(child)
        
        # Atualizar popula√ß√£o
        self.population = new_population
        self.generation += 1
        
        # Incrementar idade
        for genome in self.population:
            genome['age'] += 1
        
        return {
            'generation': self.generation,
            'best_fitness': self.best_fitness,
            'avg_fitness': np.mean([g['fitness'] for g in self.population]),
            'diversity': np.std([g['fitness'] for g in self.population])
        }

class ReinforcementLearner:
    """Sistema de aprendizado por refor√ßo"""
    
    def __init__(self, state_dim=64, action_dim=32, learning_rate=0.001):
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.learning_rate = learning_rate
        
        # Q-Network
        self.q_network = nn.Sequential(
            nn.Linear(state_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, action_dim)
        )
        
        self.target_network = nn.Sequential(
            nn.Linear(state_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, action_dim)
        )
        
        self.optimizer = torch.optim.Adam(self.q_network.parameters(), lr=learning_rate)
        
        # Experience replay
        self.memory = deque(maxlen=10000)
        self.batch_size = 32
        self.gamma = 0.99
        self.epsilon = 1.0
        self.epsilon_decay = 0.995
        self.epsilon_min = 0.01
        
        # M√©tricas
        self.total_reward = 0
        self.episode_rewards = []
    
    def select_action(self, state):
        """Sele√ß√£o de a√ß√£o epsilon-greedy"""
        if random.random() < self.epsilon:
            return random.randint(0, self.action_dim - 1)
        
        with torch.no_grad():
            state_tensor = torch.FloatTensor(state).unsqueeze(0)
            q_values = self.q_network(state_tensor)
            return q_values.argmax().item()
    
    def remember(self, state, action, reward, next_state, done):
        """Armazena experi√™ncia"""
        self.memory.append((state, action, reward, next_state, done))
    
    def replay(self):
        """Treina o modelo com replay de experi√™ncias"""
        if len(self.memory) < self.batch_size:
            return
        
        batch = random.sample(self.memory, self.batch_size)
        states = torch.FloatTensor([e[0] for e in batch])
        actions = torch.LongTensor([e[1] for e in batch])
        rewards = torch.FloatTensor([e[2] for e in batch])
        next_states = torch.FloatTensor([e[3] for e in batch])
        dones = torch.FloatTensor([e[4] for e in batch])
        
        current_q_values = self.q_network(states).gather(1, actions.unsqueeze(1))
        next_q_values = self.target_network(next_states).max(1)[0].detach()
        target_q_values = rewards + (self.gamma * next_q_values * (1 - dones))
        
        loss = F.mse_loss(current_q_values.squeeze(), target_q_values)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
        # Decay epsilon
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay
    
    def update_target_network(self):
        """Atualiza rede target"""
        self.target_network.load_state_dict(self.q_network.state_dict())

class EmergenceDetector:
    """Detector de emerg√™ncia de intelig√™ncia"""
    
    def __init__(self):
        self.metrics_history = deque(maxlen=1000)
        self.emergence_indicators = {
            'complexity': 0.0,
            'adaptability': 0.0,
            'creativity': 0.0,
            'learning_rate': 0.0,
            'self_modification': 0.0,
            'pattern_recognition': 0.0,
            'problem_solving': 0.0,
            'memory_consolidation': 0.0
        }
        self.emergence_threshold = 0.7
        self.emergence_events = []
    
    def update_metrics(self, metrics):
        """Atualiza m√©tricas de emerg√™ncia"""
        self.metrics_history.append(metrics)
        
        if len(self.metrics_history) > 10:
            # Calcular indicadores
            self._calculate_complexity()
            self._calculate_adaptability()
            self._calculate_creativity()
            self._calculate_learning_rate()
            self._calculate_pattern_recognition()
    
    def _calculate_complexity(self):
        """Calcula complexidade do sistema"""
        recent_metrics = list(self.metrics_history)[-100:]
        if recent_metrics:
            # Entropia das m√©tricas
            values = [m.get('neural_activity', 0) for m in recent_metrics]
            if values:
                hist, _ = np.histogram(values, bins=10)
                hist = hist / hist.sum()
                entropy = -np.sum(hist * np.log(hist + 1e-10))
                self.emergence_indicators['complexity'] = min(entropy / np.log(10), 1.0)
    
    def _calculate_adaptability(self):
        """Calcula adaptabilidade"""
        recent_metrics = list(self.metrics_history)[-100:]
        if len(recent_metrics) > 1:
            fitness_values = [m.get('fitness', 0) for m in recent_metrics]
            if len(fitness_values) > 1:
                improvement = (fitness_values[-1] - fitness_values[0]) / (abs(fitness_values[0]) + 1e-10)
                self.emergence_indicators['adaptability'] = min(max(improvement, 0), 1.0)
    
    def _calculate_creativity(self):
        """Calcula criatividade"""
        recent_metrics = list(self.metrics_history)[-100:]
        if recent_metrics:
            unique_solutions = len(set([str(m.get('solution', '')) for m in recent_metrics]))
            self.emergence_indicators['creativity'] = min(unique_solutions / 100.0, 1.0)
    
    def _calculate_learning_rate(self):
        """Calcula taxa de aprendizado"""
        recent_metrics = list(self.metrics_history)[-100:]
        if len(recent_metrics) > 1:
            rewards = [m.get('reward', 0) for m in recent_metrics]
            if len(rewards) > 1:
                # Taxa de melhoria
                x = np.arange(len(rewards))
                slope = np.polyfit(x, rewards, 1)[0]
                self.emergence_indicators['learning_rate'] = min(max(slope * 10, 0), 1.0)
    
    def _calculate_pattern_recognition(self):
        """Calcula reconhecimento de padr√µes"""
        recent_metrics = list(self.metrics_history)[-100:]
        if recent_metrics:
            patterns_found = sum([m.get('patterns_detected', 0) for m in recent_metrics])
            self.emergence_indicators['pattern_recognition'] = min(patterns_found / 100.0, 1.0)
    
    def check_emergence(self):
        """Verifica se h√° emerg√™ncia de intelig√™ncia"""
        emergence_score = np.mean(list(self.emergence_indicators.values()))
        
        if emergence_score > self.emergence_threshold:
            emergence_event = {
                'timestamp': datetime.now(),
                'score': emergence_score,
                'indicators': self.emergence_indicators.copy()
            }
            self.emergence_events.append(emergence_event)
            return True, emergence_score
        
        return False, emergence_score

class CompleteIntelligenceSystem:
    """Sistema completo de intelig√™ncia emergente"""
    
    def __init__(self):
        self.running = False
        
        # Componentes principais
        self.neural_processor = NeuralProcessor()
        self.evolution_engine = EvolutionEngine()
        self.reinforcement_learner = ReinforcementLearner()
        self.emergence_detector = EmergenceDetector()
        
        # Sistema de comunica√ß√£o
        self.message_queue = queue.Queue()
        
        # M√©tricas globais
        self.global_metrics = {
            'start_time': datetime.now(),
            'total_cycles': 0,
            'emergence_score': 0.0,
            'learning_events': 0,
            'evolution_generations': 0,
            'neural_processing_events': 0,
            'emergence_detected': False,
            'intelligence_level': 0.0
        }
        
        # Threads
        self.threads = []
        
        # Database para persist√™ncia
        self.db_path = "intelligence_emergence.db"
        self._initialize_database()
    
    def _initialize_database(self):
        """Inicializa banco de dados"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                metric_type TEXT,
                metric_value REAL,
                details TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS emergence_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                emergence_score REAL,
                indicators TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def save_metric(self, metric_type, metric_value, details=None):
        """Salva m√©trica no banco de dados"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO metrics (metric_type, metric_value, details)
            VALUES (?, ?, ?)
        ''', (metric_type, metric_value, json.dumps(details) if details else None))
        
        conn.commit()
        conn.close()
    
    def start_system(self):
        """Inicia o sistema completo"""
        logger.info("üöÄ INICIANDO SISTEMA COMPLETO DE EMERG√äNCIA DE INTELIG√äNCIA")
        logger.info("=" * 70)
        
        self.running = True
        
        # Iniciar threads
        self._start_neural_processing_thread()
        self._start_evolution_thread()
        self._start_reinforcement_learning_thread()
        self._start_integration_thread()
        self._start_emergence_monitoring_thread()
        
        logger.info("‚úÖ Sistema iniciado - Aguardando emerg√™ncia de intelig√™ncia...")
        
        # Loop principal
        self._main_loop()
    
    def _start_neural_processing_thread(self):
        """Thread de processamento neural"""
        def process():
            while self.running:
                try:
                    # Processar dados neurais
                    input_data = torch.randn(1, 64)
                    with torch.no_grad():
                        output = self.neural_processor(input_data)
                    
                    self.global_metrics['neural_processing_events'] += 1
                    
                    # Enviar resultado para integra√ß√£o
                    self.message_queue.put({
                        'type': 'neural_output',
                        'data': output.numpy().tolist(),
                        'timestamp': datetime.now()
                    })
                    
                    time.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"Erro no processamento neural: {e}")
                    time.sleep(1)
        
        thread = threading.Thread(target=process, daemon=True)
        thread.start()
        self.threads.append(thread)
    
    def _start_evolution_thread(self):
        """Thread de evolu√ß√£o gen√©tica"""
        def evolve():
            while self.running:
                try:
                    # Obter feedback do ambiente
                    environment_feedback = {
                        'adaptation': self.global_metrics['intelligence_level'],
                        'fitness': random.random() * 0.5 + self.global_metrics['intelligence_level'] * 0.5
                    }
                    
                    # Executar evolu√ß√£o
                    evolution_result = self.evolution_engine.evolve(environment_feedback)
                    
                    self.global_metrics['evolution_generations'] = evolution_result['generation']
                    
                    # Enviar resultado para integra√ß√£o
                    self.message_queue.put({
                        'type': 'evolution_result',
                        'data': evolution_result,
                        'timestamp': datetime.now()
                    })
                    
                    # Salvar m√©trica
                    self.save_metric('evolution_fitness', evolution_result['best_fitness'], evolution_result)
                    
                    time.sleep(1)
                    
                except Exception as e:
                    logger.error(f"Erro na evolu√ß√£o: {e}")
                    time.sleep(1)
        
        thread = threading.Thread(target=evolve, daemon=True)
        thread.start()
        self.threads.append(thread)
    
    def _start_reinforcement_learning_thread(self):
        """Thread de aprendizado por refor√ßo"""
        def learn():
            state = np.random.randn(64)
            
            while self.running:
                try:
                    # Selecionar a√ß√£o
                    action = self.reinforcement_learner.select_action(state)
                    
                    # Simular ambiente
                    next_state = np.random.randn(64)
                    reward = random.random() * self.global_metrics['intelligence_level']
                    done = random.random() < 0.01
                    
                    # Armazenar experi√™ncia
                    self.reinforcement_learner.remember(state, action, reward, next_state, done)
                    
                    # Treinar
                    self.reinforcement_learner.replay()
                    
                    # Atualizar rede target periodicamente
                    if self.global_metrics['total_cycles'] % 100 == 0:
                        self.reinforcement_learner.update_target_network()
                    
                    self.global_metrics['learning_events'] += 1
                    
                    # Enviar resultado para integra√ß√£o
                    self.message_queue.put({
                        'type': 'reinforcement_learning',
                        'data': {
                            'action': action,
                            'reward': reward,
                            'epsilon': self.reinforcement_learner.epsilon
                        },
                        'timestamp': datetime.now()
                    })
                    
                    state = next_state
                    if done:
                        state = np.random.randn(64)
                    
                    time.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"Erro no aprendizado por refor√ßo: {e}")
                    time.sleep(1)
        
        thread = threading.Thread(target=learn, daemon=True)
        thread.start()
        self.threads.append(thread)
    
    def _start_integration_thread(self):
        """Thread de integra√ß√£o dos sistemas"""
        def integrate():
            while self.running:
                try:
                    # Processar mensagens
                    messages = []
                    while not self.message_queue.empty() and len(messages) < 10:
                        messages.append(self.message_queue.get_nowait())
                    
                    if messages:
                        # Integrar informa√ß√µes
                        metrics = {
                            'neural_activity': 0,
                            'fitness': 0,
                            'reward': 0,
                            'patterns_detected': 0,
                            'solution': None
                        }
                        
                        for msg in messages:
                            if msg['type'] == 'neural_output':
                                metrics['neural_activity'] = np.mean(np.abs(msg['data']))
                                metrics['patterns_detected'] = len([x for x in msg['data'] if abs(x) > 0.5])
                            elif msg['type'] == 'evolution_result':
                                metrics['fitness'] = msg['data']['best_fitness']
                            elif msg['type'] == 'reinforcement_learning':
                                metrics['reward'] = msg['data']['reward']
                        
                        # Atualizar detector de emerg√™ncia
                        self.emergence_detector.update_metrics(metrics)
                        
                        # Calcular n√≠vel de intelig√™ncia
                        self.global_metrics['intelligence_level'] = (
                            metrics['neural_activity'] * 0.2 +
                            metrics['fitness'] * 0.3 +
                            metrics['reward'] * 0.3 +
                            (metrics['patterns_detected'] / 10.0) * 0.2
                        )
                        self.global_metrics['intelligence_level'] = min(self.global_metrics['intelligence_level'], 1.0)
                    
                    time.sleep(0.5)
                    
                except Exception as e:
                    logger.error(f"Erro na integra√ß√£o: {e}")
                    time.sleep(1)
        
        thread = threading.Thread(target=integrate, daemon=True)
        thread.start()
        self.threads.append(thread)
    
    def _start_emergence_monitoring_thread(self):
        """Thread de monitoramento de emerg√™ncia"""
        def monitor():
            while self.running:
                try:
                    # Verificar emerg√™ncia
                    emerged, score = self.emergence_detector.check_emergence()
                    self.global_metrics['emergence_score'] = score
                    
                    if emerged and not self.global_metrics['emergence_detected']:
                        self.global_metrics['emergence_detected'] = True
                        logger.info("üåü" * 30)
                        logger.info("üéâ EMERG√äNCIA DE INTELIG√äNCIA DETECTADA!")
                        logger.info(f"Score de emerg√™ncia: {score:.3f}")
                        logger.info("Indicadores:")
                        for key, value in self.emergence_detector.emergence_indicators.items():
                            logger.info(f"  {key}: {value:.3f}")
                        logger.info("üåü" * 30)
                        
                        # Salvar evento de emerg√™ncia
                        conn = sqlite3.connect(self.db_path)
                        cursor = conn.cursor()
                        cursor.execute('''
                            INSERT INTO emergence_events (emergence_score, indicators)
                            VALUES (?, ?)
                        ''', (score, json.dumps(self.emergence_detector.emergence_indicators)))
                        conn.commit()
                        conn.close()
                    
                    # Display m√©tricas
                    if self.global_metrics['total_cycles'] % 10 == 0:
                        self._display_metrics()
                    
                    time.sleep(1)
                    
                except Exception as e:
                    logger.error(f"Erro no monitoramento: {e}")
                    time.sleep(1)
        
        thread = threading.Thread(target=monitor, daemon=True)
        thread.start()
        self.threads.append(thread)
    
    def _display_metrics(self):
        """Exibe m√©tricas do sistema"""
        print("\n" + "="*70)
        print("üß† SISTEMA DE EMERG√äNCIA DE INTELIG√äNCIA")
        print("="*70)
        print(f"‚è±Ô∏è Tempo de execu√ß√£o: {datetime.now() - self.global_metrics['start_time']}")
        print(f"üîÑ Ciclos totais: {self.global_metrics['total_cycles']}")
        print(f"üß¨ Gera√ß√µes evolutivas: {self.global_metrics['evolution_generations']}")
        print(f"üéØ Eventos de aprendizado: {self.global_metrics['learning_events']}")
        print(f"‚ö° Processamento neural: {self.global_metrics['neural_processing_events']}")
        print(f"üìä N√≠vel de intelig√™ncia: {self.global_metrics['intelligence_level']:.3f}")
        print(f"üåü Score de emerg√™ncia: {self.global_metrics['emergence_score']:.3f}")
        print(f"‚ú® Emerg√™ncia detectada: {'SIM' if self.global_metrics['emergence_detected'] else 'N√ÉO'}")
        print("-" * 70)
        print("Indicadores de emerg√™ncia:")
        for key, value in self.emergence_detector.emergence_indicators.items():
            print(f"  {key}: {value:.3f}")
        print("="*70)
    
    def _main_loop(self):
        """Loop principal do sistema"""
        try:
            while self.running:
                self.global_metrics['total_cycles'] += 1
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("üõë Parando sistema...")
            self.stop_system()
    
    def stop_system(self):
        """Para o sistema"""
        self.running = False
        
        # Exibir m√©tricas finais
        self._display_metrics()
        
        # Salvar estado final
        state = {
            'global_metrics': self.global_metrics,
            'emergence_indicators': self.emergence_detector.emergence_indicators,
            'evolution_generation': self.evolution_engine.generation,
            'best_fitness': self.evolution_engine.best_fitness
        }
        
        with open('final_state.json', 'w') as f:
            json.dump(state, f, indent=2, default=str)
        
        logger.info("‚úÖ Sistema finalizado. Estado salvo em final_state.json")

def main():
    """Fun√ß√£o principal"""
    print("üöÄ SISTEMA COMPLETO DE EMERG√äNCIA DE INTELIG√äNCIA REAL")
    print("=" * 70)
    print("Componentes:")
    print("1. Processador Neural Avan√ßado com Attention e Memory Bank")
    print("2. Motor de Evolu√ß√£o Gen√©tica")
    print("3. Sistema de Aprendizado por Refor√ßo")
    print("4. Detector de Emerg√™ncia de Intelig√™ncia")
    print("5. Sistema de Integra√ß√£o e Comunica√ß√£o")
    print("=" * 70)
    
    system = CompleteIntelligenceSystem()
    
    try:
        system.start_system()
    except Exception as e:
        logger.error(f"Erro fatal: {e}")
        system.stop_system()

if __name__ == "__main__":
    main()
