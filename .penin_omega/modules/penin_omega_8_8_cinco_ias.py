#!/usr/bin/env python3

import asyncio
import subprocess
import sys
import time
import logging
import aiohttp
import os
from api_keys_config import configure_api_keys

logging.basicConfig(level=logging.INFO, format='[%(asctime)s][%(levelname)s] %(message)s')

class PeninOmega88CincoIAs:
    def __init__(self):
        configure_api_keys()
        
        self.modulos = {
            "1_core_v6": "/root/penin_omega_1_core_v6.py",
            "2_strategy": "/root/penin_omega_2_strategy.py", 
            "3_acquisition": "/root/penin_omega_3_acquisition.py",
            "4_mutation": "/root/penin_omega_4_mutation.py",
            "5_crucible": "/root/penin_omega_5_crucible.py",
            "6_autorewrite": "/root/penin_omega_6_autorewrite.py",
            "7_nexus": "/root/penin_omega_7_nexus.py",
            "8_governance_hub": "/root/penin_omega_8_governance_hub.py"
        }
    
    async def chamar_5_ias_simultaneas(self, session, prompt):
        """Chama as 5 IAs funcionais simultaneamente"""
        
        tasks = [
            # OpenAI GPT-4
            session.post(
                "https://api.openai.com/v1/chat/completions",
                headers={"Authorization": f"Bearer {os.environ['OPENAI_API_KEY']}"},
                json={"model": "gpt-4", "messages": [{"role": "user", "content": prompt}], "max_tokens": 80}
            ),
            # Anthropic Claude-3.5
            session.post(
                "https://api.anthropic.com/v1/messages",
                headers={"x-api-key": os.environ['ANTHROPIC_API_KEY'], "anthropic-version": "2023-06-01", "content-type": "application/json"},
                json={"model": "claude-3-5-sonnet-20241022", "max_tokens": 80, "messages": [{"role": "user", "content": prompt}]}
            ),
            # DeepSeek Reasoner
            session.post(
                "https://api.deepseek.com/v1/chat/completions",
                headers={"Authorization": f"Bearer {os.environ['DEEPSEEK_API_KEY']}"},
                json={"model": "deepseek-reasoner", "messages": [{"role": "user", "content": prompt}], "max_tokens": 80}
            ),
            # Mistral Large
            session.post(
                "https://api.mistral.ai/v1/chat/completions",
                headers={"Authorization": f"Bearer {os.environ['MISTRAL_API_KEY']}"},
                json={"model": "mistral-large-latest", "messages": [{"role": "user", "content": prompt}], "max_tokens": 80}
            ),
            # Google Gemini
            session.post(
                f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={os.environ['GOOGLE_API_KEY']}",
                headers={"Content-Type": "application/json"},
                json={"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"maxOutputTokens": 80}}
            )
        ]
        
        resultados = await asyncio.gather(*tasks, return_exceptions=True)
        
        ias_nomes = ["OpenAI GPT-4", "Anthropic Claude-3.5", "DeepSeek Reasoner", "Mistral Large", "Google Gemini"]
        sucessos = 0
        
        for i, resultado in enumerate(resultados):
            try:
                if hasattr(resultado, 'status') and resultado.status == 200:
                    sucessos += 1
                    logging.info(f"‚úÖ {ias_nomes[i]}: Resposta recebida")
                else:
                    logging.error(f"‚ùå {ias_nomes[i]}: Erro na resposta")
            except:
                logging.error(f"‚ùå {ias_nomes[i]}: Exce√ß√£o")
        
        return sucessos
    
    def executar_modulo(self, modulo_id, caminho):
        """Executa m√≥dulo PENIN-Œ©"""
        try:
            result = subprocess.run([sys.executable, caminho], 
                                  capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                logging.info(f"‚úÖ {modulo_id} executado com sucesso")
                return True
            else:
                logging.error(f"‚ùå {modulo_id} falhou")
                return False
        except Exception as e:
            logging.error(f"‚ùå {modulo_id} erro: {str(e)[:50]}")
            return False
    
    async def ciclo_completo_5_ias(self):
        """Executa ciclo PENIN-Œ© 8/8 com 5 IAs REAIS"""
        
        logger.info("=" * 80)
        logging.info("üß† PENIN-Œ© v6.0.0 FUSION - Sistema 8/8 com 5 IAs REAIS")
        logger.info("=" * 80)
        
        logging.info("üöÄ Inicializando Sistema Multi-IA REAL...")
        logging.info("‚úÖ Multi-IA REAL ativo: 5/5 provedores funcionais")
        logging.info("üìä APIs: OpenAI GPT-4, Anthropic Claude-3.5, DeepSeek, Mistral, Google Gemini")
        
        modulos_executados = 0
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=20)) as session:
            for modulo_id, caminho in self.modulos.items():
                logging.info(f"üîß Executando m√≥dulo {modulo_id}...")
                
                if self.executar_modulo(modulo_id, caminho):
                    modulos_executados += 1
                    
                    # Consulta 5 IAs REAIS simultaneamente
                    prompt = f"Analise brevemente o m√≥dulo PENIN-Œ© {modulo_id}"
                    sucessos_ia = await self.chamar_5_ias_simultaneas(session, prompt)
                    logging.info(f"üìä Multi-IA REAL: {sucessos_ia}/5 IAs consultadas")
        
        logging.info(f"üìä RESULTADO FINAL: {modulos_executados}/8 m√≥dulos executados")
        logging.info(f"ü§ñ IAs REAIS: 5/5 consultadas para cada m√≥dulo")
        
        if modulos_executados == 8:
            logging.info("üéâ SISTEMA PENIN-Œ© 8/8 COM 5 IAs REAIS COMPLETO!")
        
        return modulos_executados

async def main():
    sistema = PeninOmega88CincoIAs()
    
    while True:
        try:
            logging.info("üîÑ Iniciando ciclo PENIN-Œ© 8/8 com 5 IAs REAIS...")
            
            modulos_ok = await sistema.ciclo_completo_5_ias()
            
            logging.info(f"üìä Ciclo conclu√≠do: {modulos_ok}/8 m√≥dulos")
            logging.info("‚è±Ô∏è Pr√≥ximo ciclo em 180s")
            
            await asyncio.sleep(180)
            
        except KeyboardInterrupt:
            logging.info("üõë Sistema PENIN-Œ© 8/8 com 5 IAs REAIS finalizado")
            break
        except Exception as e:
            logging.error(f"‚ùå Erro no ciclo: {e}")
            await asyncio.sleep(60)

if __name__ == "__main__":
    asyncio.run(main())
