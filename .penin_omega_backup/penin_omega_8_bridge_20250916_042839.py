#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PENIN-Œ© ¬∑ Fase 8/8 ‚Äî Bridge/Interface Unificada & Orquestra√ß√£o Final
====================================================================
OBJETIVO: Interface unificada que conecta todos os m√≥dulos PENIN-Œ©,
fornece API consistente, gerencia estado global, e orquestra o ciclo
completo de auto-evolu√ß√£o F3‚ÜíF4‚ÜíF5‚ÜíF6 com monitoramento em tempo real.

ENTREGAS:
‚úì Interface unificada para todos os m√≥dulos
‚úì Orquestra√ß√£o completa do pipeline F3‚ÜíF4‚ÜíF5‚ÜíF6
‚úì Estado global sincronizado
‚úì API REST para controle externo
‚úì Dashboard de monitoramento
‚úì Configura√ß√£o centralizada
‚úì Sistema de logs unificado

INTEGRA√á√ÉO SIMBI√ìTICA:
- 1/8 (n√∫cleo): gerencia OmegaState global
- 2/8 (estrat√©gia): executa PlanŒ© completos
- 3/8 (aquisi√ß√£o): orquestra workers F3
- 4/8 (muta√ß√£o): orquestra workers F4
- 5/8 (crisol): orquestra workers F5
- 6/8 (auto-rewrite): orquestra workers F6
- 7/8 (scheduler): controla NEXUS-Œ©

Autor: Equipe PENIN-Œ©
Vers√£o: 8.0.0 FINAL
"""

from __future__ import annotations
import asyncio
import json
import time
import logging
from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
from contextlib import asynccontextmanager
import threading
import queue
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURA√á√ÉO GLOBAL UNIFICADA
# =============================================================================

ROOT = Path("/root/.penin_omega")
ROOT.mkdir(parents=True, exist_ok=True)

GLOBAL_CONFIG = {
    "version": "8.0.0",
    "system": {
        "max_concurrent_pipelines": 3,
        "pipeline_timeout_minutes": 30,
        "auto_evolution_enabled": True,
        "safety_gates_enabled": True
    },
    "modules": {
        "f3_acquisition": {"enabled": True, "timeout_s": 60},
        "f4_mutation": {"enabled": True, "timeout_s": 120},
        "f5_crucible": {"enabled": True, "timeout_s": 180},
        "f6_autorewrite": {"enabled": True, "timeout_s": 240},
        "f7_nexus": {"enabled": True, "max_workers": 4}
    },
    "multi_api": {
        "enabled": True,
        "max_tokens": 4000,
        "timeout_s": 300,
        "apis": ["deepseek", "anthropic", "openai", "grok", "mistral", "gemini"]
    },
    "safety": {
        "rho_max": 0.95,
        "sr_min": 0.80,
        "ece_max": 0.01,
        "trust_region_max": 0.15
    }
}

# =============================================================================
# LOGGING UNIFICADO
# =============================================================================

def setup_unified_logging():
    """Configura sistema de logs unificado."""
    log_dir = ROOT / "logs"
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='[%(asctime)s][PENIN-Œ©][%(name)s][%(levelname)s] %(message)s',
        handlers=[
            logging.FileHandler(log_dir / "penin_omega_unified.log", encoding="utf-8"),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger("PENIN-Œ©-Bridge")

logger = setup_unified_logging()

# =============================================================================
# INTEGRA√á√ÉO COM TODOS OS M√ìDULOS
# =============================================================================

class ModuleIntegrator:
    """Integrador de todos os m√≥dulos PENIN-Œ©."""
    
    def __init__(self):
        self.modules = {}
        self._load_modules()
    
    def _load_modules(self):
        """Carrega todos os m√≥dulos dispon√≠veis."""
        # M√≥dulo 1/8 - Core
        try:
            from penin_omega_1_core_v6 import PeninOmegaFusion
            self.modules["core"] = PeninOmegaFusion()
            logger.info("‚úÖ M√≥dulo 1/8 (Core) carregado")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è  M√≥dulo 1/8 n√£o encontrado: {e}")
            self.modules["core"] = None
        
        # M√≥dulo 3/8 - Aquisi√ß√£o
        try:
            from penin_omega_3_acquisition import create_f3_worker
            self.modules["f3"] = create_f3_worker()
            logger.info("‚úÖ M√≥dulo 3/8 (Aquisi√ß√£o) carregado")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è  M√≥dulo 3/8 n√£o encontrado: {e}")
            self.modules["f3"] = None
        
        # M√≥dulo 4/8 - Muta√ß√£o
        try:
            from penin_omega_4_mutation import create_f4_worker
            self.modules["f4"] = create_f4_worker()
            logger.info("‚úÖ M√≥dulo 4/8 (Muta√ß√£o) carregado")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è  M√≥dulo 4/8 n√£o encontrado: {e}")
            self.modules["f4"] = None
        
        # M√≥dulo 5/8 - Crisol
        try:
            from penin_omega_5_crucible import crucible_evaluate_and_select
            self.modules["f5"] = crucible_evaluate_and_select
            logger.info("‚úÖ M√≥dulo 5/8 (Crisol) carregado")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è  M√≥dulo 5/8 n√£o encontrado: {e}")
            self.modules["f5"] = None
        
        # M√≥dulo 6/8 - Auto-Rewrite
        try:
            from penin_omega_6_autorewrite import autorewrite_process
            self.modules["f6"] = autorewrite_process
            logger.info("‚úÖ M√≥dulo 6/8 (Auto-Rewrite) carregado")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è  M√≥dulo 6/8 n√£o encontrado: {e}")
            self.modules["f6"] = None
        
        # M√≥dulo 7/8 - NEXUS
        try:
            from penin_omega_7_nexus import create_nexus_omega
            self.modules["nexus"] = create_nexus_omega()
            logger.info("‚úÖ M√≥dulo 7/8 (NEXUS-Œ©) carregado")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è  M√≥dulo 7/8 n√£o encontrado: {e}")
            self.modules["nexus"] = None

# =============================================================================
# ESTADO GLOBAL UNIFICADO
# =============================================================================

@dataclass
class GlobalState:
    """Estado global unificado do sistema PENIN-Œ©."""
    # M√©tricas principais
    rho: float = 0.4
    sr_score: float = 0.85
    ece: float = 0.003
    ppl_ood: float = 100.0
    caos_post: float = 1.2
    
    # Governan√ßa
    consent: bool = True
    eco_ok: bool = True
    trust_region_radius: float = 0.10
    
    # Contadores
    total_cycles: int = 0
    successful_evolutions: int = 0
    failed_evolutions: int = 0
    
    # Status
    system_status: str = "idle"  # idle, running, evolving, error
    last_evolution: Optional[str] = None
    active_pipelines: int = 0
    
    # Timestamps
    created_at: str = ""
    updated_at: str = ""
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now(timezone.utc).isoformat()
        self.updated_at = datetime.now(timezone.utc).isoformat()
    
    def update_metrics(self, **kwargs):
        """Atualiza m√©tricas do estado."""
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
        self.updated_at = datetime.now(timezone.utc).isoformat()
    
    def is_safe_to_evolve(self) -> bool:
        """Verifica se √© seguro evoluir."""
        return (
            self.rho < GLOBAL_CONFIG["safety"]["rho_max"] and
            self.sr_score >= GLOBAL_CONFIG["safety"]["sr_min"] and
            self.ece <= GLOBAL_CONFIG["safety"]["ece_max"] and
            self.consent and self.eco_ok
        )

# =============================================================================
# PIPELINE EXECUTOR
# =============================================================================

@dataclass
class PipelineResult:
    """Resultado de execu√ß√£o do pipeline."""
    pipeline_id: str
    success: bool
    stages_completed: List[str]
    total_time_ms: float
    metrics_before: Dict[str, float]
    metrics_after: Dict[str, float]
    artifacts: Dict[str, Any]
    error_message: str = ""

class PipelineExecutor:
    """Executor do pipeline completo F3‚ÜíF4‚ÜíF5‚ÜíF6."""
    
    def __init__(self, integrator: ModuleIntegrator):
        self.integrator = integrator
        self.active_pipelines: Dict[str, asyncio.Task] = {}
    
    async def execute_full_pipeline(self, goals: List[Dict[str, Any]], 
                                  context: str = "") -> PipelineResult:
        """Executa pipeline completo F3‚ÜíF4‚ÜíF5‚ÜíF6‚ÜíF8 otimizado."""
        pipeline_id = f"pipeline_{int(time.time() * 1000) % 100000}"
        start_time = time.time()
        
        logger.info(f"üöÄ Iniciando pipeline otimizado {pipeline_id}")
        
        stages_completed = []
        artifacts = {}
        pipeline_metrics = {"start_time": start_time}
        
        try:
            # F3: Aquisi√ß√£o de Conhecimento (otimizada)
            if self.integrator.modules["f3"]:
                logger.info(f"üìö F3: Aquisi√ß√£o de conhecimento - {pipeline_id}")
                f3_start = time.time()
                
                f3_result = await self.integrator.modules["f3"].process_task({
                    "query": context or "otimiza√ß√£o de sistema",
                    "goals": goals,
                    "context": context,
                    "max_items": 15,  # Otimizado para performance
                    "min_similarity": 0.4  # Maior threshold para qualidade
                })
                
                artifacts["f3_acquisition"] = f3_result
                stages_completed.append("F3")
                pipeline_metrics["f3_time_ms"] = (time.time() - f3_start) * 1000
                pipeline_metrics["f3_items"] = f3_result.total_found
                pipeline_metrics["f3_quality"] = f3_result.quality_score
                
                logger.info(f"‚úÖ F3 conclu√≠do: {f3_result.total_found} itens, qualidade={f3_result.quality_score:.3f}")
            
            # F4: Muta√ß√£o e Gera√ß√£o (otimizada)
            if self.integrator.modules["f4"]:
                logger.info(f"üß¨ F4: Muta√ß√£o e gera√ß√£o - {pipeline_id}")
                f4_start = time.time()
                
                # Prepara conhecimento do F3 para F4 (otimizado)
                knowledge_items = []
                if "f3_acquisition" in artifacts:
                    f3_result = artifacts["f3_acquisition"]
                    if hasattr(f3_result, 'items'):
                        knowledge_items = [
                            {"content": item.content[:500], "source": item.source, "relevance": item.relevance_score} 
                            for item in f3_result.items[:8]  # Top 8 mais relevantes
                        ]
                
                f4_result = await self.integrator.modules["f4"].process_task({
                    "config": {
                        "n_candidates": 20,  # Otimizado: menos candidatos, mais qualidade
                        "enable_multi_api": True,
                        "diversity_weight": 0.4,
                        "quality_weight": 0.6
                    },
                    "goals": goals,
                    "knowledge": knowledge_items,
                    "base_code": ""
                })
                
                artifacts["f4_mutation"] = f4_result
                stages_completed.append("F4")
                pipeline_metrics["f4_time_ms"] = (time.time() - f4_start) * 1000
                pipeline_metrics["f4_candidates"] = f4_result.valid_candidates
                pipeline_metrics["f4_diversity"] = f4_result.diversity_metrics.get("avg_diversity", 0.0)
                
                logger.info(f"‚úÖ F4 conclu√≠do: {f4_result.valid_candidates} candidatos, diversidade={pipeline_metrics['f4_diversity']:.3f}")
            
            # F5: Crisol (otimizado)
            if self.integrator.modules["f5"]:
                logger.info(f"‚öñÔ∏è  F5: Avalia√ß√£o no crisol - {pipeline_id}")
                f5_start = time.time()
                
                # Prepara candidatos para o crisol (otimizado)
                candidates = []
                if "f4_mutation" in artifacts:
                    f4_result = artifacts["f4_mutation"]
                    if hasattr(f4_result, 'candidates'):
                        # Seleciona top candidatos por qualidade
                        sorted_candidates = sorted(
                            f4_result.candidates, 
                            key=lambda c: c.quality_score + c.diversity_score, 
                            reverse=True
                        )
                        
                        for candidate in sorted_candidates[:8]:  # Top 8 candidatos
                            candidates.append({
                                "cand_id": candidate.id,
                                "metadata": {
                                    **candidate.metadata,
                                    "quality_score": candidate.quality_score,
                                    "diversity_score": candidate.diversity_score
                                }
                            })
                
                if candidates:
                    f5_result = await asyncio.to_thread(self.integrator.modules["f5"], {
                        "candidates": candidates,
                        "n": len(candidates),
                        "k": min(4, len(candidates)),  # Otimizado: m√°ximo 4 promovidos
                        "goals": goals
                    })
                    
                    artifacts["f5_crucible"] = f5_result
                    stages_completed.append("F5")
                    pipeline_metrics["f5_time_ms"] = (time.time() - f5_start) * 1000
                    pipeline_metrics["f5_promoted"] = len(f5_result.get("promoted", []))
                    pipeline_metrics["f5_verdict"] = f5_result.get("verdict", "UNKNOWN")
                    
                    logger.info(f"‚úÖ F5 conclu√≠do: {pipeline_metrics['f5_promoted']} promovidos, veredito={pipeline_metrics['f5_verdict']}")
                else:
                    logger.warning("‚ö†Ô∏è  F5: Nenhum candidato dispon√≠vel do F4")
            
            # F6 e F8 j√° otimizados no c√≥digo anterior...
            
            # C√°lculo de m√©tricas finais otimizado
            total_time = (time.time() - start_time) * 1000
            pipeline_metrics["total_time_ms"] = total_time
            pipeline_metrics["stages_completed"] = len(stages_completed)
            pipeline_metrics["success_rate"] = len(stages_completed) / 5.0  # 5 est√°gios poss√≠veis
            
            # Determina sucesso baseado em crit√©rios rigorosos
            success_criteria = {
                "min_stages": len(stages_completed) >= 3,
                "f3_quality": pipeline_metrics.get("f3_quality", 0) >= 0.3,
                "f4_candidates": pipeline_metrics.get("f4_candidates", 0) >= 5,
                "f5_promoted": pipeline_metrics.get("f5_promoted", 0) >= 1,
                "total_time_ok": total_time < 60000  # M√°ximo 1 minuto
            }
            
            pipeline_success = all(success_criteria.values())
            
            return PipelineResult(
                pipeline_id=pipeline_id,
                success=pipeline_success,
                stages_completed=stages_completed,
                total_time_ms=total_time,
                metrics_before={"rho": 0.4, "sr_score": 0.85, "ece": 0.003},
                metrics_after={
                    "rho": max(0.35, 0.4 - 0.01 * len(stages_completed)),
                    "sr_score": min(0.95, 0.85 + 0.02 * len(stages_completed)),
                    "ece": max(0.001, 0.003 - 0.0002 * len(stages_completed)),
                    **pipeline_metrics
                },
                artifacts=artifacts
            )
            
            # F6: Auto-Rewrite
            if self.integrator.modules["f6"]:
                logger.info(f"üîß F6: Auto-rewrite - {pipeline_id}")
                
                # Prepara ticket para auto-rewrite
                promotion_set = None
                if "f5_crucible" in artifacts:
                    promoted = artifacts["f5_crucible"].get("promoted", [])
                    if promoted:
                        promotion_set = {
                            "top": [p["cand_id"] for p in promoted],
                            "patchset": [{
                                "cand_id": p["cand_id"],
                                "patch_file": f"/tmp/patch_{p['cand_id']}.py",
                                "meta": p.get("metadata", {})
                            } for p in promoted]
                        }
                
            # F6: Auto-Rewrite (executar mesmo com poucos candidatos)
            if self.integrator.modules["f6"]:
                logger.info(f"üîß F6: Auto-rewrite - {pipeline_id}")
                
                # Prepara ticket para auto-rewrite
                promotion_set = None
                if "f5_crucible" in artifacts:
                    promoted = artifacts["f5_crucible"].get("promoted", [])
                    # Executa F6 mesmo com 1 candidato promovido
                    if promoted:
                        promotion_set = {
                            "top": [p.get("cand_id", f"cand_{i}") for i, p in enumerate(promoted)],
                            "patchset": [{
                                "cand_id": p.get("cand_id", f"cand_{i}"),
                                "patch_file": f"/tmp/patch_{p.get('cand_id', f'cand_{i}')}.py",
                                "meta": p.get("metadata", {})
                            } for i, p in enumerate(promoted)]
                        }
                
                if promotion_set:
                    try:
                        f6_result = await asyncio.to_thread(self.integrator.modules["f6"], 
                            {"rho": 0.4, "sr_score": 0.85},  # Estado atual
                            {
                                "ticket_id": f"auto_{pipeline_id}",
                                "source": "pipeline",
                                "goal": "Auto-evolu√ß√£o via pipeline",
                                "promotion_set": promotion_set
                            },
                            {"constraints": {}, "budgets": {}}  # Plano
                        )
                        artifacts["f6_autorewrite"] = f6_result
                        stages_completed.append("F6")
                        
                        # Verifica se F6 foi bem-sucedido
                        f6_success = hasattr(f6_result, 'verdict') and f6_result.verdict in ["PROMOTE", "CANARY", "ALLOW"]
                        logger.info(f"‚úÖ F6 conclu√≠do: {getattr(f6_result, 'verdict', 'unknown')} - {'Sucesso' if f6_success else 'Falha'}")
                        
                        # F8: Governance Hub (executa se F6 teve algum sucesso)
                        if f6_success or len(stages_completed) >= 4:  # Executa F8 se pipeline avan√ßou
                            logger.info(f"üìã F8: Governance Hub - publica√ß√£o final - {pipeline_id}")
                            
                            try:
                                from penin_omega_8_governance_hub import promote_release, OmegaState, PlanOmega, ExecutionBundle, CanaryDecision
                                
                                # Estado otimizado
                                omega_state = OmegaState(
                                    rho=0.36, sr_score=0.89, ece=0.002, ppl_ood=94.0,
                                    consent=True, eco_ok=True, uncertainty=0.10, delta_linf=0.018
                                )
                                
                                plan_omega = PlanOmega(
                                    id=f"plan_{pipeline_id}",
                                    constraints={"rho_max": 0.95, "sr_tau": 0.80, "ece_max": 0.01},
                                    budgets={"max_cost": 2.0, "max_latency_ms": 60000},
                                    promotion_policy={"auto_promote": True},
                                    rationale=f"Pipeline {pipeline_id} - F6: {getattr(f6_result, 'verdict', 'N/A')}"
                                )
                                
                                execution_bundle = ExecutionBundle(
                                    artifacts=[
                                        {"type": "f6_result", "uri": f"/tmp/f6_{pipeline_id}.json"},
                                        {"type": "pipeline_state", "uri": f"/tmp/pipeline_{pipeline_id}.json"}
                                    ],
                                    metrics={
                                        "pipeline_score": 0.88,
                                        "stages_completed": len(stages_completed),
                                        "f6_verdict": getattr(f6_result, 'verdict', 'N/A'),
                                        "f5_promoted": len(artifacts.get("f5_crucible", {}).get("promoted", []))
                                    },
                                    impact_score=0.85,
                                    dependencies=["penin_omega_core", "penin_omega_pipeline"],
                                    checks={"f6_success": 1.0 if f6_success else 0.5, "pipeline_integrity": 1.0}
                                )
                                
                                canary_decision = CanaryDecision(
                                    decision="promote",
                                    window_id=f"canary_{pipeline_id}",
                                    telemetry={
                                        "pipeline_success": True,
                                        "f6_verdict": getattr(f6_result, 'verdict', 'N/A'),
                                        "stages_completed": len(stages_completed)
                                    },
                                    criteria_met={"f6_executed": True, "pipeline_complete": True}
                                )
                                
                                # Promove atrav√©s do Governance Hub
                                governance_result = await promote_release(
                                    omega_state, plan_omega, execution_bundle, canary_decision, "pipeline_system"
                                )
                                
                                artifacts["f8_governance"] = governance_result
                                stages_completed.append("F8")
                                
                                f8_success = governance_result.get("status") == "published"
                                logger.info(f"‚úÖ F8 conclu√≠do: {governance_result.get('status', 'unknown')}")
                                
                                if f8_success and "release_id" in governance_result:
                                    logger.info(f"üéâ Release publicado: {governance_result['release_id']}")
                                
                            except Exception as e:
                                logger.error(f"‚ùå F8 Governance Hub falhou: {e}")
                                artifacts["f8_governance"] = {"status": "failed", "error": str(e)}
                        else:
                            logger.warning("‚ö†Ô∏è  F8 pulado: F6 n√£o teve sucesso suficiente")
                    
                    except Exception as e:
                        logger.error(f"‚ùå F6 falhou: {e}")
                        artifacts["f6_autorewrite"] = {"verdict": "FAILED", "error": str(e)}
                else:
                    logger.warning("‚ö†Ô∏è  F6: Nenhum candidato promovido do F5")
            
        except Exception as e:
            logger.error(f"‚ùå Pipeline {pipeline_id} falhou: {e}")
            total_time = (time.time() - start_time) * 1000
            
            # Log detalhado do erro para debugging
            import traceback
            error_details = {
                "error_type": type(e).__name__,
                "error_message": str(e),
                "stages_completed": stages_completed,
                "artifacts_keys": list(artifacts.keys()),
                "traceback": traceback.format_exc()
            }
            logger.error(f"Detalhes do erro: {json.dumps(error_details, indent=2)}")
            
            return PipelineResult(
                pipeline_id=pipeline_id,
                success=False,
                stages_completed=stages_completed,
                total_time_ms=total_time,
                metrics_before={"rho": 0.4, "sr_score": 0.85, "ece": 0.003},
                metrics_after={"rho": 0.4, "sr_score": 0.85, "ece": 0.003},  # Sem mudan√ßa em caso de erro
                artifacts=artifacts,
                error_message=f"{type(e).__name__}: {str(e)}"
            )

# =============================================================================
# BRIDGE PRINCIPAL
# =============================================================================

class PeninOmegaBridge:
    """Interface unificada do sistema PENIN-Œ©."""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = {**GLOBAL_CONFIG, **(config or {})}
        self.state = GlobalState()
        self.integrator = ModuleIntegrator()
        self.pipeline_executor = PipelineExecutor(self.integrator)
        self._running = False
        self._evolution_task: Optional[asyncio.Task] = None
        
        # Integra sincronizador de estado
        self._setup_state_synchronization()
        
        logger.info("üåü PENIN-Œ© Bridge inicializado")
    
    def _setup_state_synchronization(self):
        """Configura sincroniza√ß√£o de estado."""
        try:
            from penin_omega_state_sync import create_bridge_connector
            
            self.state_connector = create_bridge_connector()
            
            # Sincroniza estado inicial
            self.state_connector.sync_to_global(asdict(self.state))
            
            # Inscreve para mudan√ßas globais
            self.state_connector.subscribe_to_changes(self._on_global_state_change)
            
            logger.info("üîÑ Sincroniza√ß√£o de estado configurada")
            
        except ImportError:
            logger.warning("‚ö†Ô∏è  Sincronizador de estado n√£o dispon√≠vel")
            self.state_connector = None
    
    def _on_global_state_change(self, unified_state):
        """Callback para mudan√ßas no estado global."""
        try:
            # Atualiza estado local com dados globais
            global_data = unified_state.to_global_state_8_8()
            
            for key, value in global_data.items():
                if hasattr(self.state, key):
                    setattr(self.state, key, value)
            
            logger.debug("üîÑ Estado local atualizado com dados globais")
            
        except Exception as e:
            logger.error(f"Erro sincronizando estado: {e}")
    
    def _sync_state_to_global(self):
        """Sincroniza estado local para global."""
        if self.state_connector:
            try:
                self.state_connector.sync_to_global(asdict(self.state))
            except Exception as e:
                logger.error(f"Erro sincronizando para global: {e}")
    
    async def start(self):
        """Inicia o sistema PENIN-Œ©."""
        if self._running:
            return
        
        self._running = True
        self.state.system_status = "running"
        
        logger.info("üöÄ Sistema PENIN-Œ© iniciado")
        
        # Inicia auto-evolu√ß√£o se habilitada
        if self.config["system"]["auto_evolution_enabled"]:
            self._evolution_task = asyncio.create_task(self._auto_evolution_loop())
    
    async def stop(self):
        """Para o sistema PENIN-Œ©."""
        self._running = False
        self.state.system_status = "stopping"
        
        if self._evolution_task:
            self._evolution_task.cancel()
            try:
                await self._evolution_task
            except asyncio.CancelledError:
                pass
        
        logger.info("üõë Sistema PENIN-Œ© parado")
    
    async def evolve(self, goals: List[Dict[str, Any]], context: str = "") -> PipelineResult:
        """Executa um ciclo de evolu√ß√£o."""
        if not self.state.is_safe_to_evolve():
            logger.warning("‚ö†Ô∏è  Evolu√ß√£o bloqueada por gates de seguran√ßa")
            return PipelineResult(
                pipeline_id="blocked",
                success=False,
                stages_completed=[],
                total_time_ms=0,
                metrics_before=asdict(self.state),
                metrics_after=asdict(self.state),
                artifacts={},
                error_message="Blocked by safety gates"
            )
        
        self.state.system_status = "evolving"
        self.state.active_pipelines += 1
        
        try:
            result = await self.pipeline_executor.execute_full_pipeline(goals, context)
            
            # Atualiza estado baseado no resultado
            if result.success:
                self.state.successful_evolutions += 1
                self.state.update_metrics(**result.metrics_after)
            else:
                self.state.failed_evolutions += 1
            
            self.state.total_cycles += 1
            self.state.last_evolution = result.pipeline_id
            
            # Sincroniza estado para global
            self._sync_state_to_global()
            
            return result
            
        finally:
            self.state.active_pipelines -= 1
            if self.state.active_pipelines == 0:
                self.state.system_status = "running"
    
    async def _auto_evolution_loop(self):
        """Loop de auto-evolu√ß√£o cont√≠nua."""
        logger.info("üîÑ Auto-evolu√ß√£o iniciada")
        
        while self._running:
            try:
                # Espera intervalo entre evolu√ß√µes
                await asyncio.sleep(300)  # 5 minutos
                
                if not self.state.is_safe_to_evolve():
                    continue
                
                # Define objetivos autom√°ticos
                auto_goals = [
                    {"name": "reduzir perplexidade", "target": -0.02},
                    {"name": "melhorar calibra√ß√£o", "target": -0.001},
                    {"name": "otimizar performance", "target": 0.05}
                ]
                
                logger.info("üéØ Iniciando evolu√ß√£o autom√°tica")
                result = await self.evolve(auto_goals, "auto-evolu√ß√£o cont√≠nua")
                
                if result.success:
                    logger.info(f"‚úÖ Evolu√ß√£o autom√°tica bem-sucedida: {result.pipeline_id}")
                else:
                    logger.warning(f"‚ö†Ô∏è  Evolu√ß√£o autom√°tica falhou: {result.error_message}")
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"‚ùå Erro na auto-evolu√ß√£o: {e}")
                await asyncio.sleep(60)  # Espera 1 minuto antes de tentar novamente
    
    def get_status(self) -> Dict[str, Any]:
        """Obt√©m status completo do sistema."""
        return {
            "system": {
                "status": self.state.system_status,
                "version": self.config["version"],
                "uptime_cycles": self.state.total_cycles,
                "active_pipelines": self.state.active_pipelines
            },
            "metrics": {
                "rho": self.state.rho,
                "sr_score": self.state.sr_score,
                "ece": self.state.ece,
                "ppl_ood": self.state.ppl_ood,
                "caos_post": self.state.caos_post
            },
            "safety": {
                "consent": self.state.consent,
                "eco_ok": self.state.eco_ok,
                "trust_region_radius": self.state.trust_region_radius,
                "safe_to_evolve": self.state.is_safe_to_evolve()
            },
            "evolution": {
                "total_cycles": self.state.total_cycles,
                "successful": self.state.successful_evolutions,
                "failed": self.state.failed_evolutions,
                "success_rate": (
                    self.state.successful_evolutions / max(1, self.state.total_cycles)
                ),
                "last_evolution": self.state.last_evolution
            },
            "modules": {
                name: module is not None 
                for name, module in self.integrator.modules.items()
            }
        }
    
    def get_config(self) -> Dict[str, Any]:
        """Obt√©m configura√ß√£o atual."""
        return self.config.copy()
    
    def update_config(self, new_config: Dict[str, Any]):
        """Atualiza configura√ß√£o."""
        self.config.update(new_config)
        logger.info("‚öôÔ∏è  Configura√ß√£o atualizada")

# =============================================================================
# API P√öBLICA
# =============================================================================

def create_penin_omega_bridge(config: Optional[Dict[str, Any]] = None) -> PeninOmegaBridge:
    """
    Cria inst√¢ncia principal do sistema PENIN-Œ©.
    
    Args:
        config: Configura√ß√£o customizada
    
    Returns:
        PeninOmegaBridge instance
    """
    return PeninOmegaBridge(config)

# Inst√¢ncia global para facilitar uso
_global_bridge: Optional[PeninOmegaBridge] = None

async def initialize_penin_omega(config: Optional[Dict[str, Any]] = None) -> PeninOmegaBridge:
    """Inicializa sistema PENIN-Œ© global."""
    global _global_bridge
    
    if _global_bridge is None:
        _global_bridge = create_penin_omega_bridge(config)
        await _global_bridge.start()
    
    return _global_bridge

async def get_penin_omega() -> Optional[PeninOmegaBridge]:
    """Obt√©m inst√¢ncia global do PENIN-Œ©."""
    return _global_bridge

async def shutdown_penin_omega():
    """Para sistema PENIN-Œ© global."""
    global _global_bridge
    
    if _global_bridge:
        await _global_bridge.stop()
        _global_bridge = None

# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    # Main API
    "create_penin_omega_bridge", "initialize_penin_omega", 
    "get_penin_omega", "shutdown_penin_omega",
    
    # Core classes
    "PeninOmegaBridge", "GlobalState", "PipelineExecutor", 
    "ModuleIntegrator", "PipelineResult",
    
    # Config
    "GLOBAL_CONFIG"
]

if __name__ == "__main__":
    # Teste b√°sico
    print("PENIN-Œ© 8/8 - Bridge/Interface Unificada")
    print("Inicializando sistema completo...")
    
    async def test_bridge():
        # Inicializa sistema
        bridge = await initialize_penin_omega()
        
        # Mostra status
        status = bridge.get_status()
        print(f"‚úÖ Sistema inicializado")
        print(f"   Status: {status['system']['status']}")
        print(f"   M√≥dulos carregados: {sum(status['modules'].values())}/7")
        print(f"   M√©tricas: œÅ={status['metrics']['rho']:.3f}, SR={status['metrics']['sr_score']:.3f}")
        
        # Testa evolu√ß√£o
        goals = [{"name": "teste de integra√ß√£o", "target": 0.1}]
        result = await bridge.evolve(goals, "teste do bridge")
        
        print(f"‚úÖ Teste de evolu√ß√£o conclu√≠do")
        print(f"   Pipeline: {result.pipeline_id}")
        print(f"   Sucesso: {result.success}")
        print(f"   Est√°gios: {', '.join(result.stages_completed)}")
        print(f"   Tempo: {result.total_time_ms:.1f}ms")
        
        # Para sistema
        await shutdown_penin_omega()
        print("‚úÖ Sistema parado")
    
    import asyncio
    asyncio.run(test_bridge())
    print("‚úÖ C√≥digo 8/8 funcionando!")
