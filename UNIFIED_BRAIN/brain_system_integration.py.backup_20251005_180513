#!/usr/bin/env python3
"""
ðŸ”— BRAIN SYSTEM INTEGRATION
Conecta o Unified Brain com V7, PENIN-Î© e Darwin
"""

import sys
sys.path.insert(0, '/root/UNIFIED_BRAIN')
sys.path.insert(0, '/root')

import torch
import torch.nn as nn
from unified_brain_core import UnifiedBrain
from intelligence_system.config.settings import (
    DATABASE_PATH,
    OFFLINE_ONLY,
    KILL_SWITCH_PATH,
)
from intelligence_system.core.database import Database
from typing import Dict, Any, List, Tuple
from dataclasses import dataclass

class BrainV7Bridge(nn.Module):
    """
    Ponte entre UnifiedBrain e sistemas V7
    """
    def __init__(self, brain: UnifiedBrain, obs_dim: int = 4, act_dim: int = 2, num_steps: int = 4):
        super().__init__()
        self.brain = brain
        H = brain.H
        self.num_steps = num_steps
        
        # Encoders: observaÃ§Ãµes â†’ Z
        self.obs_encoder = nn.Sequential(
            nn.Linear(obs_dim, H // 2),
            nn.LayerNorm(H // 2),
            nn.GELU(),
            nn.Linear(H // 2, H)
        )
        
        # Decoders: Z â†’ aÃ§Ãµes
        self.action_head = nn.Sequential(
            nn.Linear(H, H // 2),
            nn.LayerNorm(H // 2),
            nn.GELU(),
            nn.Linear(H // 2, act_dim)
        )
        
        # Value head (para PPO)
        self.value_head = nn.Sequential(
            nn.Linear(H, H // 2),
            nn.GELU(),
            nn.Linear(H // 2, 1)
        )
    
    def forward(self, obs: torch.Tensor):
        """
        obs â†’ cÃ©rebro â†’ aÃ§Ã£o + value
        """
        import time
        t0 = time.time()
        # Encode observaÃ§Ã£o para Z
        Z0 = self.obs_encoder(obs)
        t1 = time.time()
        # Processa no cÃ©rebro
        Zf = self.brain(Z0, num_steps=self.num_steps)
        t2 = time.time()
        # Decode aÃ§Ã£o e value
        logits = self.action_head(Zf)
        value = self.value_head(Zf)
        t3 = time.time()
        # Attach timings on the tensor via a dict return (avoids tensor mutation)
        timings = {
            'encode_ms': (t1 - t0) * 1000.0,
            'brain_ms': (t2 - t1) * 1000.0,
            'decode_ms': (t3 - t2) * 1000.0,
        }
        # Return logits, value, Z, and timings via attribute-like channel
        return logits, value, Zf, timings


class BrainPENINOmegaInterface:
    """
    Interface com PENIN-Î© para modulaÃ§Ã£o
    """
    def __init__(self, brain: UnifiedBrain):
        self.brain = brain
        self.L_infinity = 0.0
        self.CAOS_plus = 0.0
        self.SR_Omega_infinity = 0.0
    
    def update_signals(self, penin_metrics: Dict[str, float]):
        """Atualiza sinais de PENIN-Î©"""
        self.L_infinity = penin_metrics.get('L_infinity', 0.0)
        self.CAOS_plus = penin_metrics.get('CAOS_plus', 0.0)
        self.SR_Omega_infinity = penin_metrics.get('SR_Omega_infinity', 0.0)
        
        # Modula parÃ¢metros do cÃ©rebro
        if self.brain.router:
            # CAOS+ alto â†’ mais exploraÃ§Ã£o
            if self.CAOS_plus > 0.7:
                self.brain.router.temperature = min(2.0, self.brain.router.temperature * 1.05)
                self.brain.router.top_k = min(self.brain.max_neurons // 10, self.brain.router.top_k + 2)
            
            # Lâˆž alto â†’ menos LR, mais estabilidade
            if self.L_infinity > 0.8:
                self.brain.alpha = min(0.95, self.brain.alpha + 0.01)
                self.brain.lateral_inhibition = min(0.3, self.brain.lateral_inhibition + 0.02)
    
    def get_ia3_signal(self) -> float:
        """
        Calcula sinal IAÂ³ real do cÃ©rebro
        """
        metrics = self.brain.get_metrics_summary()
        
        # IAÂ³ = f(uso real, novidade, impacto)
        uso = metrics.get('total_activations', 0) / max(1, metrics.get('total_steps', 1))
        novidade = metrics.get('avg_novelty', 0)
        coerencia = metrics.get('avg_coherence', 0)
        
        ia3 = (uso * 0.4 + novidade * 0.3 + coerencia * 0.3)
        
        return ia3


class BrainDarwinEvolver:
    """
    Interface com Darwin para evoluÃ§Ã£o da topologia
    """
    def __init__(self, brain: UnifiedBrain):
        self.brain = brain
        self.generation = 0
        self.fitness_history = []
    
    def evaluate_fitness(self, reward: float) -> Dict[str, float]:
        """
        Avalia fitness do cÃ©rebro atual
        """
        metrics = self.brain.get_metrics_summary()
        
        # Fitness multi-objetivo
        fitness = {
            'task_reward': reward,
            'coherence': metrics.get('avg_coherence', 0),
            'novelty': metrics.get('avg_novelty', 0),
            'efficiency': 1.0 / max(1.0, metrics.get('avg_latency_ms', 1.0)),
            'diversity': len(self.brain.registry.get_active()) / max(1, self.brain.max_neurons),
        }
        
        # Fitness total (weighted)
        total_fitness = (
            fitness['task_reward'] * 0.5 +
            fitness['coherence'] * 0.2 +
            fitness['novelty'] * 0.15 +
            fitness['efficiency'] * 0.1 +
            fitness['diversity'] * 0.05
        )
        
        fitness['total'] = total_fitness
        self.fitness_history.append(total_fitness)
        
        return fitness
    
    def evolve_step(self, fitness: float):
        """
        Um passo de evoluÃ§Ã£o
        """
        # Evolui apenas adapters e router (neurÃ´nios permanecem frozen)
        
        # 1. MutaÃ§Ã£o do router
        if self.brain.router and torch.rand(1).item() < 0.1:  # 10% chance
            with torch.no_grad():
                # MutaÃ§Ã£o leve nos competence scores
                mutation = torch.randn_like(self.brain.router.competence) * 0.1
                self.brain.router.competence += mutation
                self.brain.router.competence.clamp_(0.0, 10.0)
        
        # 2. SeleÃ§Ã£o natural REAL: congela neurÃ´nios ruins
        if fitness < 0.4 and self.brain.router:
            from brain_spec import NeuronStatus
            from brain_logger import brain_logger
            
            low_comp = self.brain.router.competence < 0.5
            low_indices = torch.where(low_comp)[0].tolist()
            
            active = self.brain.registry.get_active()
            frozen_count = 0
            for idx in low_indices[:min(len(low_indices), 2)]:  # Max 2 por vez
                if idx < len(active):
                    neuron_id = active[idx].meta.id
                    self.brain.registry.promote(neuron_id, NeuronStatus.FROZEN)
                    brain_logger.warning(f"ðŸ§¬ Darwin froze {neuron_id} (competence={self.brain.router.competence[idx].item():.3f})")
                    frozen_count += 1
            
            if frozen_count > 0:
                self.brain.initialize_router()
                brain_logger.info(f"Router re-initialized: {len(self.brain.registry.get_active())} active neurons")
        
        self.generation += 1


class UnifiedSystemController:
    """
    Controlador central que orquestra tudo
    """
    def __init__(self, brain: UnifiedBrain):
        self.brain = brain
        self.v7_bridge = None  # Inicializado quando conectar V7
        self.penin_interface = BrainPENINOmegaInterface(brain)
        self.darwin_evolver = BrainDarwinEvolver(brain)
        
        self.episode_count = 0
        self.total_reward = 0.0
        # Telemetry DB
        try:
            self.db = Database(DATABASE_PATH)
        except Exception:
            self.db = None
        # Planner state (stateless by design, but keep last plan for audit)
        self._last_plan: Dict[str, Any] = {}
        # Meta-online control state
        self._config_history: list[dict] = []
        self._last_meta_decision: dict[str, Any] = {}
    
    # ----- Configuration Helpers -----
    def get_config(self) -> Dict[str, Any]:
        """Snapshot current tuning knobs (router/v7 bridge)."""
        cfg: Dict[str, Any] = {}
        try:
            r = getattr(self.brain, 'router', None)
            if r is not None:
                cfg['top_k'] = int(getattr(r, 'top_k', 0))
                cfg['temperature'] = float(getattr(r, 'temperature', 1.0))
        except Exception:
            pass
        try:
            if self.v7_bridge is not None:
                cfg['num_steps'] = int(getattr(self.v7_bridge, 'num_steps', 1))
        except Exception:
            pass
        return cfg

    def set_config(self, cfg: Dict[str, Any]) -> None:
        """Apply configuration safely with value clamping."""
        try:
            r = getattr(self.brain, 'router', None)
            if r is not None:
                if 'top_k' in cfg:
                    val = int(max(1, min(getattr(self.brain, 'max_neurons', 1024), int(cfg['top_k']))))
                    try:
                        r.top_k = val
                    except Exception:
                        pass
                if 'temperature' in cfg:
                    t = float(max(0.1, min(3.0, float(cfg['temperature']))))
                    try:
                        r.temperature = t
                    except Exception:
                        pass
        except Exception:
            pass
        try:
            if self.v7_bridge is not None and 'num_steps' in cfg:
                ns = int(max(1, min(8, int(cfg['num_steps']))))
                self.v7_bridge.num_steps = ns
        except Exception:
            pass

    def propose_meta_adjustment(self, timings_ewma: Dict[str, float], reward_avg: float) -> Dict[str, Any]:
        """Propose a small configuration change based on timings and reward trend.

        Heuristics:
        - If forward_ms or brain_ms high, reduce num_steps; if encode_ms high, reduce top_k or temperature.
        - Keep changes small (Â±1 step, Â±10% top_k, Â±5% temperature) to allow safe A/B.
        """
        base = self.get_config()
        cand = dict(base)
        fwd = float(timings_ewma.get('forward_ms', 0.0))
        enc = float(timings_ewma.get('encode_ms', 0.0))
        brn = float(timings_ewma.get('brain_ms', 0.0))
        # Defaults if missing
        if 'num_steps' not in cand:
            cand['num_steps'] = 1
        if 'top_k' not in cand:
            cand['top_k'] = 4
        if 'temperature' not in cand:
            cand['temperature'] = 1.0
        try:
            # If brain core is slow, try reducing steps by 1 (min 1)
            if brn > 5.0 or fwd > 8.0:
                cand['num_steps'] = max(1, int(cand['num_steps']) - 1)
            # If encode is slow, try reducing top_k by 10%
            if enc > 3.0:
                cand['top_k'] = max(1, int(round(cand['top_k'] * 0.9)))
            # Slightly lower temperature to stabilize if reward stagnant
            if reward_avg < 100.0:  # CartPole nominal threshold
                cand['temperature'] = max(0.8, float(cand['temperature']) * 0.95)
        except Exception:
            pass
        return cand
    
    def step(
        self,
        obs: torch.Tensor,
        penin_metrics: Dict[str, float] = None,
        reward: float = 0.0
    ) -> tuple:
        """
        Passo completo do sistema integrado
        """
        import time
        t0 = time.time()
        # 1. PENIN-Î© modula
        if penin_metrics:
            self.penin_interface.update_signals(penin_metrics)
        t1 = time.time()
        # 2. CÃ©rebro processa
        t2 = t1
        if self.v7_bridge:
            t2 = time.time()
            out = self.v7_bridge(obs)
            # Backwards compatible: older code expected 3-tuple
            if isinstance(out, tuple) and len(out) == 4:
                action_logits, value, Z, route_timings = out
            else:
                action_logits, value, Z = out
                route_timings = {'encode_ms': 0.0, 'brain_ms': 0.0, 'decode_ms': 0.0}
            t3 = time.time()
        else:
            # Sem V7, processa direto
            t2 = time.time()
            Z0 = torch.randn(obs.shape[0], self.brain.H)
            Z, info = self.brain.step(Z0, reward=reward, chaos_signal=self.penin_interface.CAOS_plus)
            action_logits = None
            value = None
            t3 = time.time()
        # 3. Darwin evolui (periodicamente)
        t4 = t3
        # 3. Darwin evolui (periodicamente)
        if self.episode_count % 10 == 0 and reward != 0:
            fitness_scores = self.darwin_evolver.evaluate_fitness(reward)
            self.darwin_evolver.evolve_step(fitness_scores['total'])
        t5 = time.time()
        # 4. IAÂ³ signal
        ia3_signal = self.penin_interface.get_ia3_signal()
        
        self.total_reward += reward
        self.episode_count += 1
        
        # 5. Persist telemetry per step (best-effort)
        try:
            if self.db and (self.episode_count % 5 == 0):
                m = self.brain.get_metrics_summary() or {}
                cart_last = reward if reward is not None else 0.0
                cart_avg = m.get('avg_energy', 0.0)  # placeholder for quick trend
                self.db.save_cycle(self.episode_count, None, cart_last, cart_avg)
                
                # BLOCO 2 - TAREFA 20: Save brain metrics
                router = self.brain.router
                if router and hasattr(router, 'competence'):
                    comp = router.competence.detach().cpu().numpy()
                    avg_comp = float(comp.mean())
                    max_comp = float(comp.max())
                    min_comp = float(comp.min())
                else:
                    avg_comp = max_comp = min_comp = 0
                
                registry = self.brain.registry
                proms = getattr(registry, 'promotion_count', 0)
                demos = getattr(registry, 'demotion_count', 0)
                
                self.db.save_brain_metrics(
                    episode=self.episode_count,
                    coherence=m.get('avg_coherence', 0),
                    novelty=m.get('avg_novelty', 0),
                    energy=m.get('avg_energy', 0),
                    ia3_signal=ia3_signal,
                    num_active_neurons=m.get('neuron_counts', {}).get('active', 0),
                    top_k=router.top_k if router else 0,
                    temperature=router.temperature if router else 0,
                    avg_competence=avg_comp,
                    max_competence=max_comp,
                    min_competence=min_comp,
                    promotions=proms,
                    demotions=demos
                )
        except Exception:
            pass

        comp_timings = {
            'penin_update_ms': (t1 - t0) * 1000.0,
            'forward_ms': (t3 - t2) * 1000.0,
            'darwin_ms': (t5 - t4) * 1000.0,
        }
        # Merge route sub-timings if available
        try:
            comp_timings.update({
                'encode_ms': float(route_timings.get('encode_ms', 0.0)),
                'brain_ms': float(route_timings.get('brain_ms', 0.0)),
                'decode_ms': float(route_timings.get('decode_ms', 0.0)),
            })
        except Exception:
            pass
        return {
            'action_logits': action_logits,
            'value': value,
            'Z': Z if self.v7_bridge is None else Z,
            'ia3_signal': ia3_signal,
            'fitness': self.darwin_evolver.fitness_history[-1] if self.darwin_evolver.fitness_history else 0.0,
            'metrics': self.brain.get_metrics_summary(),
            'timings': comp_timings,
        }

    # -------------------- Planner-Executor Scaffold --------------------
    def plan(self, goal: str, constraints: Dict[str, Any] | None = None) -> Dict[str, Any]:
        """
        Generate a checklist-style plan using LLM when OFFLINE_ONLY=0; otherwise, return a static template.
        The plan is verifiable: each step has a measurable assertion.
        """
        constraints = constraints or {}
        steps: list[dict[str, Any]] = []
        if OFFLINE_ONLY:
            steps = [
                {'step': 'collect_metrics', 'assert': 'metrics.total_steps >= prev_total_steps + 10'},
                {'step': 'run_eval_variant_noise', 'assert': 'ood_noise_score >= baseline * 1.15'},
                {'step': 'run_eval_nominal', 'assert': 'retention >= 0.90'},
            ]
        else:
            try:
                # Lazy import to avoid hard dependency
                from intelligence_system.apis.litellm_wrapper import LiteLLMWrapper
                from intelligence_system.config.settings import API_KEYS, API_MODELS
                llm = LiteLLMWrapper(API_KEYS, API_MODELS)
                prompt = (
                    f"Plan steps to improve OOD generalization for goal: {goal}. "
                    "Return 3-5 short steps with measurable asserts."
                )
                resp = llm.call_model('gemini/gemini-1.5-flash', [{'role': 'user', 'content': prompt}], max_tokens=200) or ''
                # Minimal parse: each line "- do X | assert: condition"
                for line in resp.splitlines():
                    if 'assert' in line.lower():
                        parts = line.split('|')
                        step_txt = parts[0].replace('-', '').strip()
                        assertion = parts[1].split(':', 1)[-1].strip() if len(parts) > 1 else ''
                        if step_txt:
                            steps.append({'step': step_txt, 'assert': assertion})
            except Exception:
                steps = [
                    {'step': 'collect_metrics', 'assert': 'metrics.total_steps >= prev_total_steps + 10'},
                    {'step': 'run_eval_variant_noise', 'assert': 'ood_noise_score >= baseline * 1.15'},
                    {'step': 'run_eval_nominal', 'assert': 'retention >= 0.90'},
                ]
        self._last_plan = {'goal': goal, 'constraints': constraints, 'steps': steps}
        return self._last_plan

    def execute(self, plan: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute plan steps using the brain; returns measured outcomes to validate asserts.
        """
        outcomes: Dict[str, Any] = {}
        try:
            # Reuse simple variant evaluators as proxies
            # Import locally to avoid circular imports in tests
            from unified_brain_core import CoreSoupHybrid
            hybrid = CoreSoupHybrid(H=self.brain.H)
            # No side effects here; just generate proxy scores
            def _eval_variant(var: str) -> float:
                H = hybrid.core.H
                z = torch.randn(1, H)
                score = 0.0
                for i in range(100):
                    reward = 0.5
                    if var == 'noise_high':
                        reward += float(torch.randn(1).clamp(-0.2, 0.2))
                    z, _ = hybrid.core.step(z, reward=reward)
                    score += reward
                return score / 100.0
            outcomes['ood_noise_score'] = _eval_variant('noise_high')
            outcomes['baseline'] = _eval_variant('nominal') if hasattr(torch, 'randn') else 0.5
            outcomes['retention'] = min(1.0, outcomes['baseline'] / max(1e-6, outcomes['baseline']))
        except Exception:
            pass
        return outcomes
    
    def connect_v7(self, obs_dim: int = 4, act_dim: int = 2):
        """Conecta bridge com V7"""
        self.v7_bridge = BrainV7Bridge(self.brain, obs_dim, act_dim)
        print(f"ðŸ”— V7 Bridge connected: obs_dim={obs_dim}, act_dim={act_dim}")


# -------------------- Evaluation helpers for OOD/retention gates --------------------
def _make_env(env_name: str):
    try:
        import gymnasium as gym
    except Exception:
        import gym
    return gym.make(env_name)

def evaluate_env_reward(brain: UnifiedBrain, env_name: str, episodes: int = 1,
                        noise_std: float = 0.0, obs_shift: float = 0.0,
                        max_steps: int = 500, seed: int = 0) -> float:
    """
    Avalia recompensa mÃ©dia em um ambiente Gym usando o BrainV7Bridge.
    - noise_std: desvio padrÃ£o do ruÃ­do gaussiano em observaÃ§Ãµes
    - obs_shift: deslocamento aditivo nas observaÃ§Ãµes
    """
    import torch
    import numpy as np
    torch.manual_seed(seed)
    np.random.seed(seed)

    controller = UnifiedSystemController(brain)
    # Descobrir obs_dim/act_dim dinamicamente na primeira reset
    env = _make_env(env_name)
    obs, _ = env.reset(seed=seed) if hasattr(env, 'reset') else (env.reset(), None)
    obs_dim = int(len(obs)) if hasattr(obs, '__len__') else 4
    try:
        act_dim = int(env.action_space.n)
    except Exception:
        act_dim = 2
    controller.connect_v7(obs_dim=obs_dim, act_dim=act_dim)

    total = 0.0
    for ep in range(episodes):
        obs, _ = env.reset(seed=seed + ep) if hasattr(env, 'reset') else (env.reset(), None)
        ep_reward = 0.0
        steps = 0
        done = False
        while not done and steps < max_steps:
            x = obs
            if obs_shift:
                try:
                    x = x + obs_shift
                except Exception:
                    pass
            if noise_std:
                try:
                    import numpy as _np
                    x = x + _np.random.normal(0.0, noise_std, size=_np.shape(x))
                except Exception:
                    pass
            x_t = torch.tensor(x, dtype=torch.float32).unsqueeze(0)
            with torch.inference_mode():
                logits, value, Z = controller.v7_bridge(x_t)
                action = int(torch.argmax(logits, dim=-1).item()) if logits is not None else 0
            step = env.step(action)
            if len(step) == 5:
                obs, reward, terminated, truncated, info = step
                done = bool(terminated or truncated)
            else:
                obs, reward, done, info = step
            ep_reward += float(reward)
            steps += 1
        total += ep_reward
    try:
        env.close()
    except Exception:
        pass
    return total / max(1, episodes)

def evaluate_suite(brain: UnifiedBrain, seeds: List[int]) -> Dict[str, List[float]]:
    """
    Executa uma suÃ­te OOD/nominal e retorna listas de scores por tarefa para os seeds informados.
    Tarefas:
      - cartpole_nominal, cartpole_noise, cartpole_shift, mountaincar, acrobot
    """
    suite = {
        'cartpole_nominal': dict(env='CartPole-v1', noise=0.0, shift=0.0),
        'cartpole_noise':   dict(env='CartPole-v1', noise=0.05, shift=0.0),
        'cartpole_shift':   dict(env='CartPole-v1', noise=0.0,  shift=0.1),
        'mountaincar':      dict(env='MountainCar-v0', noise=0.0, shift=0.0),
        'acrobot':          dict(env='Acrobot-v1', noise=0.0, shift=0.0),
    }
    out: Dict[str, List[float]] = {k: [] for k in suite}
    try:
        import os
        from concurrent.futures import ProcessPoolExecutor, as_completed
        episodes = int(os.getenv('UBRAIN_EVAL_EPISODES', '1'))
        parallel = int(os.getenv('UBRAIN_EVAL_PARALLEL', '0'))
        jobs: List[Tuple[str, int]] = []
        for s in seeds:
            for name in suite.keys():
                jobs.append((name, s))
        if parallel > 0:
            # Prepare static args
            def _job(args: Tuple[str, int]) -> Tuple[str, int, float]:
                name, s = args
                cfg = suite[name]
                score = evaluate_env_reward(brain, cfg['env'], episodes=episodes,
                                            noise_std=cfg['noise'], obs_shift=cfg['shift'],
                                            max_steps=500, seed=s)
                return (name, s, score)
            with ProcessPoolExecutor(max_workers=parallel) as ex:
                futures = [ex.submit(_job, j) for j in jobs]
                for fut in as_completed(futures):
                    name, s, score = fut.result()
                    out[name].append(score)
        else:
            for name, cfg in suite.items():
                for s in seeds:
                    score = evaluate_env_reward(brain, cfg['env'], episodes=episodes,
                                                noise_std=cfg['noise'], obs_shift=cfg['shift'],
                                                max_steps=500, seed=s)
                    out[name].append(score)
    except Exception:
        # Fallback serial minimal
        for name, cfg in suite.items():
            for s in seeds:
                score = evaluate_env_reward(brain, cfg['env'], episodes=1,
                                            noise_std=cfg['noise'], obs_shift=cfg['shift'],
                                            max_steps=500, seed=s)
                out[name].append(score)
    return out

# -------------------- Calibration (CartPole) --------------------
def _sigmoid(x):
    import math
    try:
        return 1.0 / (1.0 + math.exp(-float(x)))
    except Exception:
        return 0.5

def compute_regression_ece(pred: List[float], target: List[float], n_bins: int = 10) -> float:
    if not pred or not target or len(pred) != len(target):
        return 1.0
    import numpy as np
    p = np.clip(np.array(pred, dtype=float), 0.0, 1.0)
    t = np.clip(np.array(target, dtype=float), 0.0, 1.0)
    bins = np.linspace(0.0, 1.0, n_bins + 1)
    ece = 0.0
    total = len(p)
    for i in range(n_bins):
        lo, hi = bins[i], bins[i+1]
        mask = (p >= lo) & (p < hi) if i < n_bins - 1 else (p >= lo) & (p <= hi)
        if not np.any(mask):
            continue
        p_mean = float(p[mask].mean())
        t_mean = float(t[mask].mean())
        ece += abs(p_mean - t_mean) * (mask.sum() / total)
    return float(ece)

def evaluate_cartpole_calibration(brain: UnifiedBrain, seeds: List[int], episodes: int = 1) -> float:
    """Coleta (valueâ†’sigmoid) vs retorno normalizado e calcula ECE mÃ©dia."""
    import torch
    eces: List[float] = []
    for s in seeds:
        controller = UnifiedSystemController(brain)
        env = _make_env('CartPole-v1')
        obs, _ = env.reset(seed=s) if hasattr(env, 'reset') else (env.reset(), None)
        obs_dim = int(len(obs)) if hasattr(obs, '__len__') else 4
        act_dim = int(env.action_space.n) if hasattr(env, 'action_space') and hasattr(env.action_space, 'n') else 2
        controller.connect_v7(obs_dim=obs_dim, act_dim=act_dim)
        preds: List[float] = []
        trues: List[float] = []
        for ep in range(episodes):
            obs, _ = env.reset(seed=s + ep) if hasattr(env, 'reset') else (env.reset(), None)
            ep_reward = 0.0
            steps = 0
            done = False
            while not done and steps < 500:
                x_t = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)
                with torch.inference_mode():
                    logits, value, Z = controller.v7_bridge(x_t)
                # Predito: sigmoid(value)
                v = float(value.squeeze().item()) if value is not None else 0.0
                preds.append(_sigmoid(v))
                # Executa aÃ§Ã£o greedy
                action = int(torch.argmax(logits, dim=-1).item()) if logits is not None else 0
                step = env.step(action)
                if len(step) == 5:
                    obs, reward, terminated, truncated, info = step
                    done = bool(terminated or truncated)
                else:
                    obs, reward, done, info = step
                ep_reward += float(reward)
                # Verdade: retorno acumulado normalizado (aproximaÃ§Ã£o)
                trues.append(min(1.0, max(0.0, ep_reward / 500.0)))
                steps += 1
        try:
            env.close()
        except Exception:
            pass
        eces.append(compute_regression_ece(preds, trues, n_bins=10))
    return sum(eces) / max(1, len(eces))


# -------------------- Vision (MNIST-C) evaluation --------------------
def compute_classification_ece(confidences: List[float], correct: List[int], n_bins: int = 15) -> float:
    """Classification ECE using predicted-class confidence and correctness.
    Args:
        confidences: list of max softmax probabilities for predicted class (0..1)
        correct: list of 0/1 correctness indicators (1 if prediction == label)
        n_bins: number of calibration bins
    Returns:
        ECE scalar in [0, 1]
    """
    if not confidences or not correct or len(confidences) != len(correct):
        return 1.0
    import numpy as np
    p = np.clip(np.array(confidences, dtype=float), 0.0, 1.0)
    y = np.array(correct, dtype=float)
    bins = np.linspace(0.0, 1.0, n_bins + 1)
    total = len(p)
    ece = 0.0
    for i in range(n_bins):
        lo, hi = bins[i], bins[i+1]
        mask = (p >= lo) & (p < hi) if i < n_bins - 1 else (p >= lo) & (p <= hi)
        cnt = int(mask.sum())
        if cnt == 0:
            continue
        conf_bin = float(p[mask].mean())
        acc_bin = float(y[mask].mean())
        ece += abs(acc_bin - conf_bin) * (cnt / total)
    return float(ece)


def evaluate_mnist_c(model_path: str | None = None, root: str | None = None,
                     device: str = 'cpu', batch_size: int = 1024,
                     n_bins: int = 15) -> Dict[str, Any]:
    """Evaluate MNIST-C accuracy and ECE using an MNISTNet model.

    - Loads test split for each corruption from numpy arrays under root.
    - Builds a simple MNIST MLP and loads weights if available.

    Returns dict with keys: 'accuracy', 'ece', 'per_corruption', 'num_samples'.
    """
    import os
    import numpy as np
    import torch
    import torch.nn as nn
    from pathlib import Path
    # Avoid importing MNISTClassifier to prevent unintended downloads; use MNISTNet directly
    try:
        from intelligence_system.models.mnist_classifier import MNISTNet
        from intelligence_system.config.settings import MNIST_MODEL_PATH as _MNIST_MODEL_PATH
    except Exception:
        # Minimal fallback model if import path changes
        class MNISTNet(nn.Module):
            def __init__(self, hidden_size: int = 128):
                super().__init__()
                self.flatten = nn.Flatten()
                self.fc1 = nn.Linear(784, hidden_size)
                self.relu = nn.ReLU()
                self.fc2 = nn.Linear(hidden_size, 10)
            def forward(self, x):
                x = self.flatten(x)
                x = self.fc1(x)
                x = self.relu(x)
                x = self.fc2(x)
                return x
        _MNIST_MODEL_PATH = Path('/root/intelligence_system/models/mnist_model.pth')

    root_dir = Path(root or '/root/data/mnist_c')
    if not root_dir.exists():
        raise FileNotFoundError(f"MNIST-C directory not found at {root_dir}")

    # Build model and load weights if present
    model = MNISTNet().to(device)
    path = Path(model_path) if model_path else Path(_MNIST_MODEL_PATH)
    if path.exists():
        try:
            ckpt = torch.load(path, map_location=device)
            state = ckpt.get('model_state_dict', ckpt if isinstance(ckpt, dict) else None)
            if isinstance(state, dict):
                model.load_state_dict(state, strict=False)
        except Exception:
            pass
    model.eval()

    softmax = nn.Softmax(dim=1)
    total = 0
    correct_total = 0
    confidences: List[float] = []
    correctness: List[int] = []
    per_corr_acc: Dict[str, float] = {}

    # Iterate corruptions; stream batches to limit memory
    for corr_dir in sorted([p for p in root_dir.iterdir() if p.is_dir()]):
        try:
            X = np.load(corr_dir / 'test_images.npy')  # shape [N, 28, 28]
            y = np.load(corr_dir / 'test_labels.npy')  # shape [N]
        except Exception:
            # Some distributions may use 'test_images'/'labels' without .npy, skip
            try:
                X = np.load(str(corr_dir / 'test_images'))
                y = np.load(str(corr_dir / 'test_labels'))
            except Exception:
                continue
        N = int(X.shape[0])
        if N == 0:
            continue
        
        # BUG FIX C2: Sample to avoid timeout (500 samples per corruption)
        import os as _os
        sample_size = int(_os.getenv('MNISTC_SAMPLE_SIZE', '500'))
        if N > sample_size:
            idx = np.random.choice(N, sample_size, replace=False)
            X = X[idx]
            y = y[idx]
            N = sample_size
        # Normalize to [0,1] and add channel dimension
        # Use batches to avoid OOM
        corr_correct = 0
        bs = max(1, int(batch_size))
        for i in range(0, N, bs):
            xb = X[i:i+bs]
            yb = y[i:i+bs]
            xb = torch.tensor(xb, dtype=torch.float32, device=device) / 255.0
            if xb.ndim == 3:
                xb = xb.unsqueeze(1)  # [B,1,28,28]
            with torch.inference_mode():
                logits = model(xb)
                probs = softmax(logits)
                conf, pred = torch.max(probs, dim=1)
            preds_np = pred.detach().cpu().numpy()
            conf_np = conf.detach().cpu().numpy()
            y_np = np.array(yb, dtype=np.int64)
            corr = (preds_np == y_np).astype(np.int32)
            corr_correct += int(corr.sum())
            total += len(y_np)
            correct_total += int(corr.sum())
            confidences.extend([float(c) for c in conf_np.tolist()])
            correctness.extend([int(c) for c in corr.tolist()])
        per_corr_acc[corr_dir.name] = float(corr_correct / max(1, N))

    accuracy = float(correct_total / max(1, total))
    ece = compute_classification_ece(confidences, correctness, n_bins=n_bins)

    return {
        'accuracy': accuracy,
        'ece': ece,
        'per_corruption': per_corr_acc,
        'num_samples': int(total),
        'model_path': str(path),
        'root': str(root_dir),
    }


if __name__ == "__main__":
    print("ðŸ”— Brain System Integration Module")
    print("Use UnifiedSystemController to orchestrate everything")
