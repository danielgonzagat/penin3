#!/usr/bin/env python3
"""
üß™ SUITE COMPLETA DE TESTES - FASE 2
Cobertura: 18% ‚Üí 60%
"""

import sys
sys.path.insert(0, '/root/UNIFIED_BRAIN')

import torch
import torch.nn as nn
from pathlib import Path
import time
import gc
import json

from unified_brain_core import UnifiedBrain, CoreSoupHybrid
from brain_spec import RegisteredNeuron, NeuronMeta, NeuronStatus, NeuronRegistry
from brain_router import AdaptiveRouter, IA3Router
from brain_system_integration import UnifiedSystemController, BrainV7Bridge
from brain_worm import WORMLog
from brain_logger import brain_logger

print("="*80)
print("üß™ COMPREHENSIVE TEST SUITE - FASE 2")
print("="*80)
print()

tests_passed = 0
tests_failed = 0
test_results = []

def test(name, fn, category="general"):
    """Helper para rodar teste"""
    global tests_passed, tests_failed
    
    print(f"TEST: {name}")
    start = time.time()
    
    try:
        fn()
        elapsed = time.time() - start
        tests_passed += 1
        test_results.append({
            'name': name,
            'category': category,
            'status': 'PASSED',
            'time': elapsed
        })
        print(f"   ‚úÖ PASSED ({elapsed:.2f}s)\n")
        return True
    except AssertionError as e:
        elapsed = time.time() - start
        tests_failed += 1
        test_results.append({
            'name': name,
            'category': category,
            'status': 'FAILED',
            'error': str(e),
            'time': elapsed
        })
        print(f"   ‚ùå FAILED: {e}\n")
        return False
    except Exception as e:
        elapsed = time.time() - start
        tests_failed += 1
        test_results.append({
            'name': name,
            'category': category,
            'status': 'CRASHED',
            'error': str(e),
            'time': elapsed
        })
        print(f"   üí• CRASHED: {e}\n")
        return False

# ============================================================================
# CATEGORY 1: CORE FUNCTIONALITY
# ============================================================================
print("="*80)
print("CATEGORY 1: CORE FUNCTIONALITY")
print("="*80)
print()

def test_registry_large():
    """Registry com 10k neurons"""
    registry = NeuronRegistry()
    
    for i in range(10000):
        meta = NeuronMeta(
            id=f'n{i}',
            in_shape=(1024,),
            out_shape=(1024,),
            dtype=torch.float32,
            device='cpu',
            status=NeuronStatus.ACTIVE,
            source='test',
            params_count=0,
            checksum=f'test{i}'
        )
        neuron = RegisteredNeuron(meta, lambda x: x, H=1024)
        registry.register(neuron)
    
    assert registry.count()['total'] == 10000
    assert registry.count()['active'] == 10000
    
    # Cleanup
    del registry
    gc.collect()

def test_long_run():
    """Long run 1000 steps sem crash"""
    hybrid = CoreSoupHybrid(H=1024)
    hybrid.core.registry.load_with_adapters('/root/UNIFIED_BRAIN/snapshots/initial_state_registry.json')
    hybrid.core.initialize_router()
    
    z = torch.randn(1, 1024)
    for i in range(1000):
        z, info = hybrid.core.step(z, reward=0.5)
        # Gate invariants: never select more than active neurons
        active_count = hybrid.core.registry.count()['active']
        assert info['selected_neurons'] <= active_count
        if i % 200 == 0:
            print(f"      Step {i}/1000")
    
    assert hybrid.core.step_count >= 1000

def test_snapshot_save_load():
    """Snapshot save/load completo"""
    brain = UnifiedBrain(H=1024, max_neurons=100, top_k=16)
    
    # Adiciona neurons
    for i in range(10):
        meta = NeuronMeta(
            id=f'n{i}',
            in_shape=(1024,),
            out_shape=(1024,),
            dtype=torch.float32,
            device='cpu',
            status=NeuronStatus.ACTIVE,
            source='test',
            params_count=0,
            checksum=f'test{i}'
        )
        neuron = RegisteredNeuron(meta, lambda x: x, H=1024)
        brain.register_neuron(neuron)
    
    brain.initialize_router()
    
    # Roda steps
    z = torch.randn(1, 1024)
    for _ in range(10):
        z, _ = brain.step(z)
    
    steps_before = brain.step_count
    
    # Salva
    brain.save_snapshot("/tmp/test_snapshot.pt")
    
    # Carrega
    brain2 = UnifiedBrain(H=1024, max_neurons=100, top_k=16)
    brain2.registry.load_with_adapters("/tmp/neuron_registry.json")
    brain2.load_snapshot("/tmp/test_snapshot.pt")
    # Verify WORM or integrity via manifest not available here
    
    assert brain2.step_count == steps_before

def test_kill_switch():
    """Kill switch funciona"""
    brain = UnifiedBrain(H=1024, max_neurons=100, top_k=16)
    
    # Cria kill switch
    Path("/root/STOP_BRAIN").touch()
    
    z = torch.randn(1, 1024)
    z_out, info = brain.step(z)
    
    assert info['status'] == 'stopped'
    assert brain.is_active == False
    
    # Limpa
    Path("/root/STOP_BRAIN").unlink()

def test_adapter_quality():
    """Adapters calibrados reduzem erro"""
    meta = NeuronMeta(
        id='test',
        in_shape=(1024,),
        out_shape=(1024,),
        dtype=torch.float32,
        device='cpu',
        status=NeuronStatus.ACTIVE,
        source='test',
        params_count=0,
        checksum='test'
    )
    
    neuron = RegisteredNeuron(meta, lambda x: x * 0.5, H=1024)
    
    # Erro ANTES
    probes = torch.randn(100, 1024)
    z_out_before = neuron.forward_in_Z(probes[:20])
    error_before = (z_out_before - probes[:20]).pow(2).mean().item()
    
    # Calibra
    loss = neuron.calibrate_adapters(probes, epochs=20, lr=1e-3)
    
    # Erro DEPOIS
    z_out_after = neuron.forward_in_Z(probes[:20])
    error_after = (z_out_after - probes[:20]).pow(2).mean().item()
    
    # Deve melhorar
    assert error_after < error_before * 1.2  # Aceita 20% toler√¢ncia

# Run Core Tests
test("Registry 10k neurons", test_registry_large, "core")
test("Long run 1000 steps", test_long_run, "core")
test("Snapshot save/load", test_snapshot_save_load, "core")
test("Kill switch", test_kill_switch, "core")
test("Adapter calibration quality", test_adapter_quality, "core")

# ============================================================================
# CATEGORY 2: ROUTER & ADAPTATION
# ============================================================================
print("="*80)
print("CATEGORY 2: ROUTER & ADAPTATION")
print("="*80)
print()

def test_router_adaptation():
    """Router adapta par√¢metros"""
    router = AdaptiveRouter(H=1024, num_neurons=100, top_k=10)
    
    top_k_before = router.top_k
    temp_before = router.temperature
    
    # High reward ‚Üí exploit
    for _ in range(20):
        router.adapt_parameters(reward=0.95, chaos_signal=0.0)
    
    # Top-k deve diminuir, temp tamb√©m
    assert router.top_k <= top_k_before

def test_router_ema_decay():
    """EMA decay adapta"""
    router = AdaptiveRouter(H=1024, num_neurons=100, top_k=10)
    
    ema_before = router.ema_decay
    
    # High performance
    for _ in range(20):
        router.adapt_parameters(reward=0.9, chaos_signal=0.0)
    
    ema_after = router.ema_decay
    
    # Deve ter mudado
    assert abs(ema_after - ema_before) > 1e-6

def test_competence_updates():
    """Competence scores atualizam"""
    router = AdaptiveRouter(H=1024, num_neurons=100, top_k=10)
    
    comp_before = router.competence[0].item()
    
    # Positive rewards
    for _ in range(10):
        router.update_competence(0, reward=1.0, lr=0.1)
    
    comp_after = router.competence[0].item()
    
    assert comp_after > comp_before

# Run Router Tests
test("Router adaptation", test_router_adaptation, "router")
test("Router EMA decay", test_router_ema_decay, "router")
test("Competence updates", test_competence_updates, "router")

# ============================================================================
# CATEGORY 3: INTEGRATION
# ============================================================================
print("="*80)
print("CATEGORY 3: INTEGRATION")
print("="*80)
print()

def test_v7_bridge():
    """V7 bridge funciona"""
    brain = UnifiedBrain(H=1024, max_neurons=100, top_k=16)
    bridge = BrainV7Bridge(brain, obs_dim=4, act_dim=2)
    
    obs = torch.randn(8, 4)  # Batch
    logits, value, Z = bridge(obs)
    
    assert logits.shape == (8, 2)
    assert value.shape == (8, 1)
    assert Z.shape[0] == 8

def test_worm_integrity():
    """WORM chain mant√©m integridade"""
    worm = WORMLog("/root/test_worm_integrity.log")
    
    # Adiciona 100 eventos
    for i in range(100):
        worm.append(f'event_{i}', {'step': i})
    
    # Verifica integridade
    assert worm.verify_chain()
    
    stats = worm.get_stats()
    assert stats['total_entries'] >= 100
    assert stats['chain_valid']

def test_full_system():
    """Sistema completo integrado"""
    hybrid = CoreSoupHybrid(H=1024)
    snapshot = Path("/root/UNIFIED_BRAIN/snapshots/initial_state_registry.json")
    
    if snapshot.exists():
        hybrid.core.registry.load_with_adapters(str(snapshot))
        hybrid.core.initialize_router()
        
        controller = UnifiedSystemController(hybrid.core)
        controller.connect_v7(obs_dim=4, act_dim=2)
        
        # Roda 50 steps
        obs = torch.randn(1, 4)
        for i in range(50):
            result = controller.step(
                obs=obs,
                penin_metrics={'L_infinity': 0.5, 'CAOS_plus': 0.3},
                reward=0.5
            )
            
            if i == 25:
                # Verifica WORM
                stats = hybrid.core.worm.get_stats()
                assert stats['total_entries'] > 25
        
        assert True
    else:
        assert False, "No snapshot found"

# Run Integration Tests
test("V7 Bridge", test_v7_bridge, "integration")
test("WORM integrity", test_worm_integrity, "integration")
test("Full system", test_full_system, "integration")

# ============================================================================
# CATEGORY 4: PERFORMANCE
# ============================================================================
print("="*80)
print("CATEGORY 4: PERFORMANCE")
print("="*80)
print()

def test_latency():
    """Lat√™ncia aceit√°vel"""
    hybrid = CoreSoupHybrid(H=1024)
    hybrid.core.registry.load_with_adapters('/root/UNIFIED_BRAIN/snapshots/initial_state_registry.json')
    hybrid.core.initialize_router()
    
    z = torch.randn(1, 1024)
    start = time.time()
    
    for _ in range(100):
        z, _ = hybrid.core.step(z)
    
    elapsed = time.time() - start
    avg_latency = elapsed / 100 * 1000
    
    print(f"      Avg latency: {avg_latency:.2f}ms")
    
    # Deve ser < 150ms
    assert avg_latency < 150, f"Too slow: {avg_latency:.2f}ms"

def test_memory_stable():
    """Mem√≥ria n√£o cresce descontroladamente"""
    import psutil
    import os
    
    process = psutil.Process(os.getpid())
    mem_before = process.memory_info().rss / 1024**2
    
    # Roda 500 steps
    hybrid = CoreSoupHybrid(H=1024)
    hybrid.core.registry.load_with_adapters('/root/UNIFIED_BRAIN/snapshots/initial_state_registry.json')
    hybrid.core.initialize_router()
    
    z = torch.randn(1, 1024)
    for i in range(500):
        z, _ = hybrid.core.step(z)
        if i % 100 == 0:
            gc.collect()
    
    mem_after = process.memory_info().rss / 1024**2
    growth = mem_after - mem_before
    
    print(f"      Memory growth: {growth:.1f}MB")
    
    # Aceita at√© 200MB de crescimento
    assert growth < 200, f"Memory leak: {growth:.1f}MB"

# ============================================================================
# CATEGORY 5: GENERALIZATION (OOD GATES)
# ============================================================================
print("="*80)
print("CATEGORY 5: GENERALIZATION (OOD GATES)")
print("="*80)
print()

def _evaluate_task_variant(hybrid: CoreSoupHybrid, variant: str, steps: int = 200) -> float:
    """Evaluate brain on a simple synthetic variant producing a scalar score."""
    torch.manual_seed(42)
    H = hybrid.core.H
    score = 0.0
    z = torch.randn(1, H)
    for i in range(steps):
        # Variant perturbs reward shaping
        reward = 0.5
        if variant == 'noise_high':
            reward += float(torch.randn(1).clamp(-0.2, 0.2))
        elif variant == 'sparse_reward':
            reward = 1.0 if (i % 25 == 0) else 0.0
        elif variant == 'shifted_distribution':
            z = z + 0.05 * torch.randn_like(z)
        z, _info = hybrid.core.step(z, reward=reward)
        score += reward
    return score / max(1, steps)

def test_generalization_ood_gate():
    """Require ‚â•15% uplift vs baseline on held-out variants and ‚â•90% retention."""
    hybrid = CoreSoupHybrid(H=1024)
    snapshot = Path("/root/UNIFIED_BRAIN/snapshots/initial_state_registry.json")
    assert snapshot.exists(), "Snapshot required for OOD gate"
    hybrid.core.registry.load_with_adapters(str(snapshot))
    hybrid.core.initialize_router()

    # Baseline on nominal distribution
    base = _evaluate_task_variant(hybrid, variant='nominal', steps=150)

    # OOD variants
    v_noise = _evaluate_task_variant(hybrid, variant='noise_high', steps=150)
    v_sparse = _evaluate_task_variant(hybrid, variant='sparse_reward', steps=150)
    v_shift = _evaluate_task_variant(hybrid, variant='shifted_distribution', steps=150)

    ood_avg = (v_noise + v_sparse + v_shift) / 3.0

    # Gate: uplift ‚â• 15% vs baseline on OOD average
    uplift = (ood_avg - base) / max(1e-6, abs(base))
    # Retention proxy: performance on nominal after OOD exposure ‚â• 90% baseline
    base_after = _evaluate_task_variant(hybrid, variant='nominal', steps=150)
    retention = base_after / max(1e-6, abs(base))

    print(f"      base={base:.4f}, ood_avg={ood_avg:.4f}, uplift={uplift*100:.1f}% , retention={retention*100:.1f}%")
    assert uplift >= 0.15, f"OOD uplift too low: {uplift*100:.1f}% < 15%"
    assert retention >= 0.90, f"Retention too low: {retention*100:.1f}% < 90%"

# Run Generalization Tests
test("OOD Gate (‚â•15% uplift & ‚â•90% retention)", test_generalization_ood_gate, "generalization")

# Run Performance Tests
test("Latency < 150ms", test_latency, "performance")
test("Memory stable", test_memory_stable, "performance")

# ============================================================================
# RESULTS
# ============================================================================
print("="*80)
print("üìä FINAL RESULTS")
print("="*80)
print()

total = tests_passed + tests_failed
print(f"‚úÖ PASSED:  {tests_passed}/{total} ({tests_passed/total*100:.1f}%)")
print(f"‚ùå FAILED:  {tests_failed}/{total} ({tests_failed/total*100:.1f}%)")
print()

# Por categoria
categories = {}
for result in test_results:
    cat = result['category']
    if cat not in categories:
        categories[cat] = {'passed': 0, 'failed': 0}
    
    if result['status'] == 'PASSED':
        categories[cat]['passed'] += 1
    else:
        categories[cat]['failed'] += 1

print("By Category:")
for cat, stats in categories.items():
    total_cat = stats['passed'] + stats['failed']
    pct = stats['passed'] / total_cat * 100
    print(f"   {cat}: {stats['passed']}/{total_cat} ({pct:.0f}%)")

print()

# Salva resultados
results_file = Path("/root/UNIFIED_BRAIN/test_results_comprehensive.json")
with open(results_file, 'w') as f:
    json.dump({
        'total_tests': total,
        'passed': tests_passed,
        'failed': tests_failed,
        'pass_rate': tests_passed / total * 100,
        'categories': categories,
        'individual_results': test_results
    }, f, indent=2)

print(f"üíæ Results saved: {results_file}")
print()

if tests_failed == 0:
    print("üéä ALL TESTS PASSED!")
    print("   Coverage: 18% ‚Üí 60% estimated")
else:
    print("‚ö†Ô∏è  Some tests failed - review before production")

print("="*80)
